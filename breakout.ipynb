{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBIOKKreXHVaT+j5qOB+zy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahsank/StockML/blob/main/breakout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q yahoo_fin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7t5Edurdd2N",
        "outputId": "a793ffdb-668e-42e6-ac3c-a61975a61418"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a51PqrJVdInN"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from yahoo_fin import stock_info as si\n",
        "from collections import deque\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "from tensorflow.keras.layers import LSTM\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loaddataBO(alldf, steps=12, shuffle=True, skip=6, lookup=60,\n",
        "               split_by_date=True, target=\"pct_target\", test_size=0.2,\n",
        "               features = [\"pct_close\", \"pct_vol\"]):\n",
        "    xdata, ydata = [], []\n",
        "    alldf = alldf[alldf.close > 0]\n",
        "    alldf = alldf[alldf.vol > 1000]\n",
        "    tickers = alldf.ticker.unique()\n",
        "    last_seq = []\n",
        "    alldf.loc[:, 'pct_vol'] = alldf['vol'].pct_change()\n",
        "    alldf.loc[:, 'pct_close'] = alldf['close'].pct_change()\n",
        "    alldf.loc[:, 'mean_close'] = alldf['close'].rolling(steps).mean()\n",
        "    alldf.dropna(inplace=True)\n",
        "    for ticker in tickers:\n",
        "        last_row = alldf[alldf.ticker == ticker].tail(steps)[features]\n",
        "        assert not last_row.isnull().values.any()\n",
        "        if len(last_row) > 0:\n",
        "            last_seq.append(np.array(last_row))\n",
        "    last_seq = np.array(last_seq)\n",
        "    alldf.loc[:, 'target'] = alldf.loc[:, 'close'].rolling(lookup).max().shift(-lookup)\n",
        "    alldf.dropna(inplace=True)\n",
        "    alldf.loc[:, 'pct_target'] = alldf['target']/alldf['mean_close']\n",
        "    alldf.dropna(inplace=True)\n",
        "\n",
        "    scale = 5.0\n",
        "    alldf['scale_target'] = alldf['pct_target'].apply(lambda x:  min(x,scale)*2.0/scale - 1)\n",
        "\n",
        "#    alldf.dropna(inplace=True)\n",
        "    alldf['timestamp'] = pd.to_datetime(alldf['timestamp'])\n",
        "    for ticker in tickers:\n",
        "        lasttime = None\n",
        "        tickerdf = alldf[alldf.ticker == ticker]\n",
        "        predx = tickerdf.tail(steps)[features]\n",
        "\n",
        "        for i in range(len(tickerdf)-steps-lookup):\n",
        "            if lasttime is None:\n",
        "                lasttime = tickerdf.iloc[i].timestamp\n",
        "\n",
        "            if tickerdf.iloc[i].timestamp < lasttime:\n",
        "                continue\n",
        "            else:\n",
        "                lasttime = lasttime + relativedelta(months=skip)\n",
        "\n",
        "            # start_row = i\n",
        "            # end_row = i+steps\n",
        "            # xrow = tickerdf.iloc[end_row-1, :]\n",
        "            # tsi = xrow.timestamp\n",
        "            # closei = xrow.close\n",
        "            # checktime = tsi + relativedelta(months=lookup)\n",
        "            # mean_value = tickerdf.iloc[start_row:end_row]['close'].mean()\n",
        "            # rate = closei / mean_value\n",
        "            rate = tickerdf.iloc[i+steps-1][target]\n",
        "            seq = tickerdf.iloc[i:i+steps][features]\n",
        "            xdata.append(np.array(seq))\n",
        "            ydata.append(rate)\n",
        "    xdata = np.array(xdata)\n",
        "    ydata = np.array(ydata)\n",
        "    if split_by_date:\n",
        "        train_samples = int((1-test_size) * len(xdata))\n",
        "        xtrain = xdata[:train_samples]\n",
        "        ytrain = ydata[:train_samples]\n",
        "        xtest = xdata[train_samples:]\n",
        "        ytest = ydata[train_samples:]\n",
        "    else:\n",
        "        xtrain, xtest, ytrain, ytest = train_tst_split(xdata, ydata, test_size=test_size, shuffle=shuffle)\n",
        "    xtrain = xtrain[:, :, :len(features)].astype(np.float32)\n",
        "    last_seq = last_seq[:, :, :len(features)].astype(np.float32)\n",
        "    xtest = xtest[:, :, :len(features)].astype(np.float32)\n",
        "    return xtrain, ytrain, xtest, ytest, (tickers, last_seq)\n"
      ],
      "metadata": {
        "id": "be-f_ZlgdTYG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(sequence_length, n_features, units=256, cell=LSTM,\n",
        "                 n_layers=2, dropout=0.4,\n",
        "                 loss=\"huber_loss\", optimizer=\"adam\", bidirectional=True):\n",
        "    model = Sequential()\n",
        "    for i in range(n_layers):\n",
        "        if i == 0:\n",
        "            # first layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
        "        elif i == n_layers - 1:\n",
        "            # last layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=False))\n",
        "        else:\n",
        "            # hidden layers\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True))\n",
        "        # add dropout after each layer\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Dense(1, activation=\"linear\"))\n",
        "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "mfd3dCDXeF3P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mytrain(model_name, model, xtrain,\n",
        "            ytrain, xtest, ytest, epochs, batch_size=64):\n",
        "    checkpointer = ModelCheckpoint(\"test.h5\", save_weights_only=True,\n",
        "                                   save_best_only = True, verbose=1)\n",
        "    tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
        "    earlystopping = EarlyStopping(monitor='loss', patience=5)\n",
        "    model.fit(xtrain, ytrain, batch_size=batch_size, epochs=epochs,\n",
        "              validation_data=(xtest, ytest),\n",
        "              callbacks = [checkpointer, tensorboard, earlystopping],\n",
        "              verbose=1)\n"
      ],
      "metadata": {
        "id": "Hf5-52DReKeo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_op(alldf=None, model=None, epoch=10):\n",
        "    if alldf is None:\n",
        "        alldf = pd.read_csv(\"alldf.csv\")\n",
        "    xtrain, ytrain, xtest, ytest, pred_pair = loaddataBO(alldf)\n",
        "    if model is None:\n",
        "        model = create_model(12, 2)\n",
        "    mytrain(\"testmodel\", model, xtrain, ytrain, xtest, ytest, epoch)\n",
        "    result = {}\n",
        "    tickers, last_seq = pred_pair\n",
        "    preds = model.predict(last_seq)\n",
        "    result = pd.DataFrame({'ticker': tickers, 'pred': preds[:, 0]})\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "lCtSWK7reO79"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}