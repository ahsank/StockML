{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iRWFgIbnzajB",
        "scrolled": true,
        "outputId": "cd305729-bd74-4487-8ae7-a19b098d337a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/81.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "pip install -q yahoo_fin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-bcZhdWxMtx"
      },
      "outputs": [],
      "source": [
        "pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zmGhmDpxMtx"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0MuPGKaH3W59"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data results logs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mfX08b_RbeEb",
        "outputId": "4e7b66e0-fe16-4f7d-c742-d7c295c57f77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74aXCtye0_Ty"
      },
      "outputs": [],
      "source": [
        "! cp ~/Google\\ Drive/My\\ Drive/colab/results/* ./results/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4AuykWZdTyh"
      },
      "source": [
        "Todos:\n",
        "\n",
        " \n",
        "\n",
        "1.   Load previously saved model before training\n",
        "2.   Allow eval only without test/train spliting\n",
        "3.   Incremental data load\n",
        "4.    Add S&P, QQQ etc to the model\n",
        "5. Save model to google drive\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32PM9X_JRFbK"
      },
      "source": [
        "Run following in local Jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqx81EuXwsnI",
        "outputId": "22237b2a-ca44-4798-9d16-eff76b356124"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/ahsank/src/runml\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "path = os.path.expanduser('~/src/runml')\n",
        "print(path)\n",
        "if not path in sys.path:\n",
        "  sys.path.append(path)\n",
        "\n",
        "from runml import pipeline,findata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESjiEs5XRLK2"
      },
      "source": [
        "Run following 2 cells for colab to import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2nveD-MH1LMt",
        "outputId": "776bab23-ad92-4c52-a1c1-913e04a16425",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'runml'...\n",
            "remote: Enumerating objects: 634, done.\u001b[K\n",
            "remote: Counting objects: 100% (167/167), done.\u001b[K\n",
            "remote: Compressing objects: 100% (140/140), done.\u001b[K\n",
            "remote: Total 634 (delta 110), reused 35 (delta 27), pack-reused 467\u001b[K\n",
            "Receiving objects: 100% (634/634), 4.17 MiB | 3.18 MiB/s, done.\n",
            "Resolving deltas: 100% (398/398), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ahsank/runml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4oFRGi7vxYym"
      },
      "outputs": [],
      "source": [
        "import importlib\n",
        "import sys\n",
        "path = 'runml'\n",
        "if not path in sys.path:\n",
        "  sys.path.append(path)\n",
        "\n",
        "from runml import pipeline,findata\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK-XpE7cRXCB"
      },
      "source": [
        "Run following if the library code is modified locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADNm6CsPxMty",
        "outputId": "73856c71-dfae-4580-95bd-105b210e23d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'runml.findata' from '/content/runml/runml/findata.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from importlib import reload\n",
        "reload(pipeline)\n",
        "reload(findata)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# profit factor 2 = 50% of predicted gain due to early profit taking\n",
        "def addAlloc(df, stop_loss, profit_factor=2):\n",
        "  df['Alloc'] = df['Accuracy']/stop_loss - (1-df['Accuracy'])*profit_factor/abs(df['Gain'])\n",
        "  df['Alloc'] = np.where(df['Alloc'] < 0, 0, df['Alloc'])\n",
        "  return df"
      ],
      "metadata": {
        "id": "kcdzATEECevL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NRNq5x6mTG-q",
        "scrolled": true,
        "outputId": "7709d2f1-1c9b-4177-b0de-45ee9375bd23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0055 - mean_absolute_error: 0.0769\n",
            "Epoch 1: val_loss improved from inf to 0.00412, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 19s 14ms/step - loss: 0.0055 - mean_absolute_error: 0.0769 - val_loss: 0.0041 - val_mean_absolute_error: 0.0666\n",
            "Epoch 2/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0047 - mean_absolute_error: 0.0710\n",
            "Epoch 2: val_loss improved from 0.00412 to 0.00388, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 0.0047 - mean_absolute_error: 0.0710 - val_loss: 0.0039 - val_mean_absolute_error: 0.0638\n",
            "Epoch 3/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0043 - mean_absolute_error: 0.0679\n",
            "Epoch 3: val_loss improved from 0.00388 to 0.00379, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0043 - mean_absolute_error: 0.0679 - val_loss: 0.0038 - val_mean_absolute_error: 0.0636\n",
            "Epoch 4/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0042 - mean_absolute_error: 0.0669\n",
            "Epoch 4: val_loss improved from 0.00379 to 0.00378, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0042 - mean_absolute_error: 0.0669 - val_loss: 0.0038 - val_mean_absolute_error: 0.0634\n",
            "Epoch 5/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0041 - mean_absolute_error: 0.0658\n",
            "Epoch 5: val_loss improved from 0.00378 to 0.00341, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 0.0041 - mean_absolute_error: 0.0658 - val_loss: 0.0034 - val_mean_absolute_error: 0.0592\n",
            "Epoch 6/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0039 - mean_absolute_error: 0.0645\n",
            "Epoch 6: val_loss did not improve from 0.00341\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0039 - mean_absolute_error: 0.0645 - val_loss: 0.0035 - val_mean_absolute_error: 0.0598\n",
            "Epoch 7/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0038 - mean_absolute_error: 0.0635\n",
            "Epoch 7: val_loss improved from 0.00341 to 0.00330, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0038 - mean_absolute_error: 0.0635 - val_loss: 0.0033 - val_mean_absolute_error: 0.0580\n",
            "Epoch 8/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0037 - mean_absolute_error: 0.0627\n",
            "Epoch 8: val_loss improved from 0.00330 to 0.00326, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0037 - mean_absolute_error: 0.0627 - val_loss: 0.0033 - val_mean_absolute_error: 0.0586\n",
            "Epoch 9/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0036 - mean_absolute_error: 0.0621\n",
            "Epoch 9: val_loss improved from 0.00326 to 0.00324, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 0.0036 - mean_absolute_error: 0.0621 - val_loss: 0.0032 - val_mean_absolute_error: 0.0590\n",
            "Epoch 10/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0036 - mean_absolute_error: 0.0619\n",
            "Epoch 10: val_loss did not improve from 0.00324\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 0.0036 - mean_absolute_error: 0.0619 - val_loss: 0.0033 - val_mean_absolute_error: 0.0593\n",
            "Epoch 11/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0035 - mean_absolute_error: 0.0613\n",
            "Epoch 11: val_loss improved from 0.00324 to 0.00318, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 0.0035 - mean_absolute_error: 0.0613 - val_loss: 0.0032 - val_mean_absolute_error: 0.0576\n",
            "Epoch 12/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0035 - mean_absolute_error: 0.0610\n",
            "Epoch 12: val_loss improved from 0.00318 to 0.00317, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 0.0035 - mean_absolute_error: 0.0609 - val_loss: 0.0032 - val_mean_absolute_error: 0.0568\n",
            "Epoch 13/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0034 - mean_absolute_error: 0.0603\n",
            "Epoch 13: val_loss improved from 0.00317 to 0.00305, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0034 - mean_absolute_error: 0.0603 - val_loss: 0.0031 - val_mean_absolute_error: 0.0558\n",
            "Epoch 14/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0034 - mean_absolute_error: 0.0602\n",
            "Epoch 14: val_loss did not improve from 0.00305\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 0.0034 - mean_absolute_error: 0.0602 - val_loss: 0.0031 - val_mean_absolute_error: 0.0570\n",
            "Epoch 15/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0033 - mean_absolute_error: 0.0594\n",
            "Epoch 15: val_loss improved from 0.00305 to 0.00301, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 0.0033 - mean_absolute_error: 0.0594 - val_loss: 0.0030 - val_mean_absolute_error: 0.0553\n",
            "Epoch 16/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0033 - mean_absolute_error: 0.0590\n",
            "Epoch 16: val_loss did not improve from 0.00301\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0033 - mean_absolute_error: 0.0590 - val_loss: 0.0031 - val_mean_absolute_error: 0.0561\n",
            "Epoch 17/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0032 - mean_absolute_error: 0.0589\n",
            "Epoch 17: val_loss improved from 0.00301 to 0.00286, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0032 - mean_absolute_error: 0.0589 - val_loss: 0.0029 - val_mean_absolute_error: 0.0546\n",
            "Epoch 18/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0032 - mean_absolute_error: 0.0582\n",
            "Epoch 18: val_loss did not improve from 0.00286\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0032 - mean_absolute_error: 0.0582 - val_loss: 0.0029 - val_mean_absolute_error: 0.0548\n",
            "Epoch 19/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0031 - mean_absolute_error: 0.0576\n",
            "Epoch 19: val_loss did not improve from 0.00286\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0031 - mean_absolute_error: 0.0576 - val_loss: 0.0029 - val_mean_absolute_error: 0.0542\n",
            "Epoch 20/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0030 - mean_absolute_error: 0.0566\n",
            "Epoch 20: val_loss improved from 0.00286 to 0.00272, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 0.0030 - mean_absolute_error: 0.0566 - val_loss: 0.0027 - val_mean_absolute_error: 0.0532\n",
            "Epoch 21/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0029 - mean_absolute_error: 0.0562\n",
            "Epoch 21: val_loss improved from 0.00272 to 0.00270, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 0.0029 - mean_absolute_error: 0.0562 - val_loss: 0.0027 - val_mean_absolute_error: 0.0527\n",
            "Epoch 22/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0029 - mean_absolute_error: 0.0558\n",
            "Epoch 22: val_loss improved from 0.00270 to 0.00268, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0029 - mean_absolute_error: 0.0558 - val_loss: 0.0027 - val_mean_absolute_error: 0.0527\n",
            "Epoch 23/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0028 - mean_absolute_error: 0.0547\n",
            "Epoch 23: val_loss improved from 0.00268 to 0.00261, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0028 - mean_absolute_error: 0.0547 - val_loss: 0.0026 - val_mean_absolute_error: 0.0522\n",
            "Epoch 24/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.0543\n",
            "Epoch 24: val_loss improved from 0.00261 to 0.00257, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 0.0027 - mean_absolute_error: 0.0543 - val_loss: 0.0026 - val_mean_absolute_error: 0.0513\n",
            "Epoch 25/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0536\n",
            "Epoch 25: val_loss improved from 0.00257 to 0.00241, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0026 - mean_absolute_error: 0.0536 - val_loss: 0.0024 - val_mean_absolute_error: 0.0501\n",
            "Epoch 26/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0526\n",
            "Epoch 26: val_loss did not improve from 0.00241\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0025 - mean_absolute_error: 0.0526 - val_loss: 0.0024 - val_mean_absolute_error: 0.0508\n",
            "Epoch 27/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0521\n",
            "Epoch 27: val_loss improved from 0.00241 to 0.00230, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0025 - mean_absolute_error: 0.0521 - val_loss: 0.0023 - val_mean_absolute_error: 0.0495\n",
            "Epoch 28/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0513\n",
            "Epoch 28: val_loss improved from 0.00230 to 0.00222, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0024 - mean_absolute_error: 0.0513 - val_loss: 0.0022 - val_mean_absolute_error: 0.0489\n",
            "Epoch 29/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0508\n",
            "Epoch 29: val_loss improved from 0.00222 to 0.00213, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0023 - mean_absolute_error: 0.0508 - val_loss: 0.0021 - val_mean_absolute_error: 0.0478\n",
            "Epoch 30/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0495\n",
            "Epoch 30: val_loss improved from 0.00213 to 0.00209, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 0.0022 - mean_absolute_error: 0.0495 - val_loss: 0.0021 - val_mean_absolute_error: 0.0469\n",
            "Epoch 31/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0488\n",
            "Epoch 31: val_loss improved from 0.00209 to 0.00190, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 0.0021 - mean_absolute_error: 0.0488 - val_loss: 0.0019 - val_mean_absolute_error: 0.0450\n",
            "Epoch 32/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0477\n",
            "Epoch 32: val_loss did not improve from 0.00190\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0020 - mean_absolute_error: 0.0477 - val_loss: 0.0020 - val_mean_absolute_error: 0.0462\n",
            "Epoch 33/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0471\n",
            "Epoch 33: val_loss did not improve from 0.00190\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0020 - mean_absolute_error: 0.0471 - val_loss: 0.0020 - val_mean_absolute_error: 0.0464\n",
            "Epoch 34/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0460\n",
            "Epoch 34: val_loss improved from 0.00190 to 0.00173, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0019 - mean_absolute_error: 0.0460 - val_loss: 0.0017 - val_mean_absolute_error: 0.0429\n",
            "Epoch 35/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0452\n",
            "Epoch 35: val_loss improved from 0.00173 to 0.00159, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0018 - mean_absolute_error: 0.0452 - val_loss: 0.0016 - val_mean_absolute_error: 0.0415\n",
            "Epoch 36/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0439\n",
            "Epoch 36: val_loss did not improve from 0.00159\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0017 - mean_absolute_error: 0.0439 - val_loss: 0.0018 - val_mean_absolute_error: 0.0449\n",
            "Epoch 37/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0431\n",
            "Epoch 37: val_loss improved from 0.00159 to 0.00146, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 0.0016 - mean_absolute_error: 0.0431 - val_loss: 0.0015 - val_mean_absolute_error: 0.0407\n",
            "Epoch 38/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0419\n",
            "Epoch 38: val_loss did not improve from 0.00146\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 0.0015 - mean_absolute_error: 0.0419 - val_loss: 0.0015 - val_mean_absolute_error: 0.0408\n",
            "Epoch 39/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0412\n",
            "Epoch 39: val_loss improved from 0.00146 to 0.00140, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0015 - mean_absolute_error: 0.0412 - val_loss: 0.0014 - val_mean_absolute_error: 0.0400\n",
            "Epoch 40/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0403\n",
            "Epoch 40: val_loss improved from 0.00140 to 0.00125, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 0.0014 - mean_absolute_error: 0.0403 - val_loss: 0.0013 - val_mean_absolute_error: 0.0374\n",
            "Epoch 41/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0393\n",
            "Epoch 41: val_loss improved from 0.00125 to 0.00121, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0013 - mean_absolute_error: 0.0393 - val_loss: 0.0012 - val_mean_absolute_error: 0.0366\n",
            "Epoch 42/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0388\n",
            "Epoch 42: val_loss improved from 0.00121 to 0.00115, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0013 - mean_absolute_error: 0.0388 - val_loss: 0.0012 - val_mean_absolute_error: 0.0358\n",
            "Epoch 43/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0378\n",
            "Epoch 43: val_loss did not improve from 0.00115\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0012 - mean_absolute_error: 0.0378 - val_loss: 0.0012 - val_mean_absolute_error: 0.0373\n",
            "Epoch 44/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0373\n",
            "Epoch 44: val_loss improved from 0.00115 to 0.00112, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 0.0012 - mean_absolute_error: 0.0373 - val_loss: 0.0011 - val_mean_absolute_error: 0.0356\n",
            "Epoch 45/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0362\n",
            "Epoch 45: val_loss did not improve from 0.00112\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0011 - mean_absolute_error: 0.0362 - val_loss: 0.0012 - val_mean_absolute_error: 0.0353\n",
            "Epoch 46/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0358\n",
            "Epoch 46: val_loss improved from 0.00112 to 0.00103, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0011 - mean_absolute_error: 0.0358 - val_loss: 0.0010 - val_mean_absolute_error: 0.0338\n",
            "Epoch 47/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0347\n",
            "Epoch 47: val_loss did not improve from 0.00103\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0010 - mean_absolute_error: 0.0347 - val_loss: 0.0011 - val_mean_absolute_error: 0.0345\n",
            "Epoch 48/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 9.9956e-04 - mean_absolute_error: 0.0344\n",
            "Epoch 48: val_loss did not improve from 0.00103\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 9.9980e-04 - mean_absolute_error: 0.0344 - val_loss: 0.0010 - val_mean_absolute_error: 0.0341\n",
            "Epoch 49/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 9.6409e-04 - mean_absolute_error: 0.0338\n",
            "Epoch 49: val_loss improved from 0.00103 to 0.00093, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 9.6490e-04 - mean_absolute_error: 0.0338 - val_loss: 9.3349e-04 - val_mean_absolute_error: 0.0322\n",
            "Epoch 50/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 9.0761e-04 - mean_absolute_error: 0.0329\n",
            "Epoch 50: val_loss improved from 0.00093 to 0.00087, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 9.0761e-04 - mean_absolute_error: 0.0329 - val_loss: 8.7457e-04 - val_mean_absolute_error: 0.0313\n",
            "Epoch 51/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 8.9880e-04 - mean_absolute_error: 0.0327\n",
            "Epoch 51: val_loss did not improve from 0.00087\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 8.9880e-04 - mean_absolute_error: 0.0327 - val_loss: 9.0542e-04 - val_mean_absolute_error: 0.0319\n",
            "Epoch 52/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 8.6482e-04 - mean_absolute_error: 0.0321\n",
            "Epoch 52: val_loss improved from 0.00087 to 0.00083, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 8.6482e-04 - mean_absolute_error: 0.0321 - val_loss: 8.2980e-04 - val_mean_absolute_error: 0.0308\n",
            "Epoch 53/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 8.1890e-04 - mean_absolute_error: 0.0312\n",
            "Epoch 53: val_loss improved from 0.00083 to 0.00079, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 8.1866e-04 - mean_absolute_error: 0.0312 - val_loss: 7.9004e-04 - val_mean_absolute_error: 0.0301\n",
            "Epoch 54/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 8.0445e-04 - mean_absolute_error: 0.0310\n",
            "Epoch 54: val_loss did not improve from 0.00079\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 8.0445e-04 - mean_absolute_error: 0.0310 - val_loss: 9.3455e-04 - val_mean_absolute_error: 0.0329\n",
            "Epoch 55/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 8.1595e-04 - mean_absolute_error: 0.0310\n",
            "Epoch 55: val_loss did not improve from 0.00079\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 8.1597e-04 - mean_absolute_error: 0.0310 - val_loss: 8.4899e-04 - val_mean_absolute_error: 0.0305\n",
            "Epoch 56/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 7.6901e-04 - mean_absolute_error: 0.0302\n",
            "Epoch 56: val_loss did not improve from 0.00079\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 7.6871e-04 - mean_absolute_error: 0.0302 - val_loss: 7.9751e-04 - val_mean_absolute_error: 0.0300\n",
            "Epoch 57/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 7.3737e-04 - mean_absolute_error: 0.0296\n",
            "Epoch 57: val_loss improved from 0.00079 to 0.00072, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 7.3755e-04 - mean_absolute_error: 0.0296 - val_loss: 7.1971e-04 - val_mean_absolute_error: 0.0284\n",
            "Epoch 58/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 7.0953e-04 - mean_absolute_error: 0.0291\n",
            "Epoch 58: val_loss did not improve from 0.00072\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 7.0960e-04 - mean_absolute_error: 0.0291 - val_loss: 7.5246e-04 - val_mean_absolute_error: 0.0289\n",
            "Epoch 59/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 7.2061e-04 - mean_absolute_error: 0.0292\n",
            "Epoch 59: val_loss did not improve from 0.00072\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 7.2046e-04 - mean_absolute_error: 0.0292 - val_loss: 7.5266e-04 - val_mean_absolute_error: 0.0293\n",
            "Epoch 60/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 7.1438e-04 - mean_absolute_error: 0.0290\n",
            "Epoch 60: val_loss did not improve from 0.00072\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 7.1500e-04 - mean_absolute_error: 0.0291 - val_loss: 0.0011 - val_mean_absolute_error: 0.0337\n",
            "Epoch 61/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 7.0413e-04 - mean_absolute_error: 0.0287\n",
            "Epoch 61: val_loss improved from 0.00072 to 0.00064, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 7.0442e-04 - mean_absolute_error: 0.0287 - val_loss: 6.3623e-04 - val_mean_absolute_error: 0.0266\n",
            "Epoch 62/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 7.3031e-04 - mean_absolute_error: 0.0290\n",
            "Epoch 62: val_loss did not improve from 0.00064\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 7.2984e-04 - mean_absolute_error: 0.0290 - val_loss: 6.7775e-04 - val_mean_absolute_error: 0.0268\n",
            "Epoch 63/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 6.5572e-04 - mean_absolute_error: 0.0277\n",
            "Epoch 63: val_loss did not improve from 0.00064\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 6.5571e-04 - mean_absolute_error: 0.0277 - val_loss: 6.8955e-04 - val_mean_absolute_error: 0.0268\n",
            "Epoch 64/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 6.3672e-04 - mean_absolute_error: 0.0275\n",
            "Epoch 64: val_loss did not improve from 0.00064\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 6.3705e-04 - mean_absolute_error: 0.0275 - val_loss: 6.3913e-04 - val_mean_absolute_error: 0.0268\n",
            "Epoch 65/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 6.1437e-04 - mean_absolute_error: 0.0270\n",
            "Epoch 65: val_loss improved from 0.00064 to 0.00062, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 6.1427e-04 - mean_absolute_error: 0.0270 - val_loss: 6.1607e-04 - val_mean_absolute_error: 0.0260\n",
            "Epoch 66/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 6.2249e-04 - mean_absolute_error: 0.0271\n",
            "Epoch 66: val_loss did not improve from 0.00062\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 6.2245e-04 - mean_absolute_error: 0.0271 - val_loss: 6.6366e-04 - val_mean_absolute_error: 0.0272\n",
            "Epoch 67/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 5.8385e-04 - mean_absolute_error: 0.0264\n",
            "Epoch 67: val_loss improved from 0.00062 to 0.00056, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 5.8351e-04 - mean_absolute_error: 0.0263 - val_loss: 5.5786e-04 - val_mean_absolute_error: 0.0249\n",
            "Epoch 68/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 5.8276e-04 - mean_absolute_error: 0.0264\n",
            "Epoch 68: val_loss did not improve from 0.00056\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 5.8263e-04 - mean_absolute_error: 0.0264 - val_loss: 6.2341e-04 - val_mean_absolute_error: 0.0266\n",
            "Epoch 69/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 5.6671e-04 - mean_absolute_error: 0.0259\n",
            "Epoch 69: val_loss did not improve from 0.00056\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 5.6735e-04 - mean_absolute_error: 0.0259 - val_loss: 5.6085e-04 - val_mean_absolute_error: 0.0249\n",
            "Epoch 70/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 5.7209e-04 - mean_absolute_error: 0.0261\n",
            "Epoch 70: val_loss did not improve from 0.00056\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 5.7194e-04 - mean_absolute_error: 0.0261 - val_loss: 5.9196e-04 - val_mean_absolute_error: 0.0255\n",
            "Epoch 71/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 5.3758e-04 - mean_absolute_error: 0.0253\n",
            "Epoch 71: val_loss improved from 0.00056 to 0.00055, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 5.3712e-04 - mean_absolute_error: 0.0252 - val_loss: 5.5228e-04 - val_mean_absolute_error: 0.0246\n",
            "Epoch 72/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 5.4153e-04 - mean_absolute_error: 0.0253\n",
            "Epoch 72: val_loss improved from 0.00055 to 0.00054, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 5.4141e-04 - mean_absolute_error: 0.0253 - val_loss: 5.3829e-04 - val_mean_absolute_error: 0.0242\n",
            "Epoch 73/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 5.3940e-04 - mean_absolute_error: 0.0253\n",
            "Epoch 73: val_loss did not improve from 0.00054\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 5.3929e-04 - mean_absolute_error: 0.0253 - val_loss: 5.9102e-04 - val_mean_absolute_error: 0.0252\n",
            "Epoch 74/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 5.0885e-04 - mean_absolute_error: 0.0245\n",
            "Epoch 74: val_loss improved from 0.00054 to 0.00047, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 5.0918e-04 - mean_absolute_error: 0.0245 - val_loss: 4.6686e-04 - val_mean_absolute_error: 0.0228\n",
            "Epoch 75/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 5.0154e-04 - mean_absolute_error: 0.0244\n",
            "Epoch 75: val_loss did not improve from 0.00047\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 5.0125e-04 - mean_absolute_error: 0.0244 - val_loss: 5.1077e-04 - val_mean_absolute_error: 0.0235\n",
            "Epoch 76/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 5.2001e-04 - mean_absolute_error: 0.0247\n",
            "Epoch 76: val_loss did not improve from 0.00047\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 5.1979e-04 - mean_absolute_error: 0.0247 - val_loss: 5.0242e-04 - val_mean_absolute_error: 0.0234\n",
            "Epoch 77/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 4.9792e-04 - mean_absolute_error: 0.0243\n",
            "Epoch 77: val_loss did not improve from 0.00047\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 4.9792e-04 - mean_absolute_error: 0.0243 - val_loss: 4.6995e-04 - val_mean_absolute_error: 0.0228\n",
            "Epoch 78/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 4.8082e-04 - mean_absolute_error: 0.0238\n",
            "Epoch 78: val_loss did not improve from 0.00047\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 4.8082e-04 - mean_absolute_error: 0.0238 - val_loss: 5.0221e-04 - val_mean_absolute_error: 0.0234\n",
            "Epoch 79/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 4.7311e-04 - mean_absolute_error: 0.0237\n",
            "Epoch 79: val_loss did not improve from 0.00047\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 4.7349e-04 - mean_absolute_error: 0.0237 - val_loss: 5.3482e-04 - val_mean_absolute_error: 0.0241\n",
            "Epoch 80/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 4.8331e-04 - mean_absolute_error: 0.0239\n",
            "Epoch 80: val_loss did not improve from 0.00047\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 4.8336e-04 - mean_absolute_error: 0.0239 - val_loss: 5.0174e-04 - val_mean_absolute_error: 0.0236\n",
            "Epoch 81/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 4.8008e-04 - mean_absolute_error: 0.0237\n",
            "Epoch 81: val_loss did not improve from 0.00047\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 4.8024e-04 - mean_absolute_error: 0.0237 - val_loss: 4.9628e-04 - val_mean_absolute_error: 0.0231\n",
            "Epoch 82/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 4.4901e-04 - mean_absolute_error: 0.0230\n",
            "Epoch 82: val_loss did not improve from 0.00047\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 4.4901e-04 - mean_absolute_error: 0.0230 - val_loss: 4.9045e-04 - val_mean_absolute_error: 0.0231\n",
            "Epoch 83/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 4.6002e-04 - mean_absolute_error: 0.0233\n",
            "Epoch 83: val_loss did not improve from 0.00047\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 4.5996e-04 - mean_absolute_error: 0.0233 - val_loss: 4.7000e-04 - val_mean_absolute_error: 0.0228\n",
            "Epoch 84/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 4.8707e-04 - mean_absolute_error: 0.0237\n",
            "Epoch 84: val_loss improved from 0.00047 to 0.00043, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 4.8691e-04 - mean_absolute_error: 0.0237 - val_loss: 4.3461e-04 - val_mean_absolute_error: 0.0215\n",
            "Epoch 85/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 4.3166e-04 - mean_absolute_error: 0.0226\n",
            "Epoch 85: val_loss did not improve from 0.00043\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 4.3129e-04 - mean_absolute_error: 0.0226 - val_loss: 4.3502e-04 - val_mean_absolute_error: 0.0217\n",
            "Epoch 86/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 4.3343e-04 - mean_absolute_error: 0.0226\n",
            "Epoch 86: val_loss did not improve from 0.00043\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 4.3455e-04 - mean_absolute_error: 0.0226 - val_loss: 6.6829e-04 - val_mean_absolute_error: 0.0255\n",
            "Epoch 87/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 4.4687e-04 - mean_absolute_error: 0.0229\n",
            "Epoch 87: val_loss did not improve from 0.00043\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 4.4687e-04 - mean_absolute_error: 0.0229 - val_loss: 4.5934e-04 - val_mean_absolute_error: 0.0221\n",
            "Epoch 88/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 4.3449e-04 - mean_absolute_error: 0.0226\n",
            "Epoch 88: val_loss improved from 0.00043 to 0.00043, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 4.3451e-04 - mean_absolute_error: 0.0226 - val_loss: 4.2965e-04 - val_mean_absolute_error: 0.0214\n",
            "Epoch 89/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 4.1935e-04 - mean_absolute_error: 0.0222\n",
            "Epoch 89: val_loss did not improve from 0.00043\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 4.1935e-04 - mean_absolute_error: 0.0222 - val_loss: 4.3423e-04 - val_mean_absolute_error: 0.0215\n",
            "Epoch 90/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 4.2354e-04 - mean_absolute_error: 0.0222\n",
            "Epoch 90: val_loss did not improve from 0.00043\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 4.2378e-04 - mean_absolute_error: 0.0222 - val_loss: 4.9071e-04 - val_mean_absolute_error: 0.0228\n",
            "Epoch 91/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 4.3172e-04 - mean_absolute_error: 0.0225\n",
            "Epoch 91: val_loss improved from 0.00043 to 0.00043, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 4.3172e-04 - mean_absolute_error: 0.0225 - val_loss: 4.2622e-04 - val_mean_absolute_error: 0.0212\n",
            "Epoch 92/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 4.0524e-04 - mean_absolute_error: 0.0219\n",
            "Epoch 92: val_loss improved from 0.00043 to 0.00041, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 4.0529e-04 - mean_absolute_error: 0.0219 - val_loss: 4.0929e-04 - val_mean_absolute_error: 0.0208\n",
            "Epoch 93/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 4.0916e-04 - mean_absolute_error: 0.0219\n",
            "Epoch 93: val_loss did not improve from 0.00041\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 4.0916e-04 - mean_absolute_error: 0.0219 - val_loss: 4.2355e-04 - val_mean_absolute_error: 0.0211\n",
            "Epoch 94/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 4.0939e-04 - mean_absolute_error: 0.0219\n",
            "Epoch 94: val_loss did not improve from 0.00041\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 4.0938e-04 - mean_absolute_error: 0.0219 - val_loss: 4.4215e-04 - val_mean_absolute_error: 0.0215\n",
            "Epoch 95/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.9930e-04 - mean_absolute_error: 0.0216\n",
            "Epoch 95: val_loss did not improve from 0.00041\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.9913e-04 - mean_absolute_error: 0.0216 - val_loss: 4.2169e-04 - val_mean_absolute_error: 0.0213\n",
            "Epoch 96/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.9997e-04 - mean_absolute_error: 0.0216\n",
            "Epoch 96: val_loss did not improve from 0.00041\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 4.0009e-04 - mean_absolute_error: 0.0216 - val_loss: 4.7526e-04 - val_mean_absolute_error: 0.0217\n",
            "Epoch 97/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.9595e-04 - mean_absolute_error: 0.0216\n",
            "Epoch 97: val_loss did not improve from 0.00041\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.9561e-04 - mean_absolute_error: 0.0215 - val_loss: 4.1565e-04 - val_mean_absolute_error: 0.0207\n",
            "Epoch 98/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.7883e-04 - mean_absolute_error: 0.0212\n",
            "Epoch 98: val_loss improved from 0.00041 to 0.00040, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.7891e-04 - mean_absolute_error: 0.0212 - val_loss: 3.9703e-04 - val_mean_absolute_error: 0.0206\n",
            "Epoch 99/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 3.8963e-04 - mean_absolute_error: 0.0214\n",
            "Epoch 99: val_loss did not improve from 0.00040\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.8984e-04 - mean_absolute_error: 0.0214 - val_loss: 3.9720e-04 - val_mean_absolute_error: 0.0204\n",
            "Epoch 100/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 4.0072e-04 - mean_absolute_error: 0.0216\n",
            "Epoch 100: val_loss did not improve from 0.00040\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 4.0037e-04 - mean_absolute_error: 0.0216 - val_loss: 4.1004e-04 - val_mean_absolute_error: 0.0206\n",
            "Epoch 101/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.7624e-04 - mean_absolute_error: 0.0210\n",
            "Epoch 101: val_loss did not improve from 0.00040\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.7606e-04 - mean_absolute_error: 0.0210 - val_loss: 4.1004e-04 - val_mean_absolute_error: 0.0204\n",
            "Epoch 102/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 3.9537e-04 - mean_absolute_error: 0.0213\n",
            "Epoch 102: val_loss did not improve from 0.00040\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.9540e-04 - mean_absolute_error: 0.0213 - val_loss: 4.0460e-04 - val_mean_absolute_error: 0.0205\n",
            "Epoch 103/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.7247e-04 - mean_absolute_error: 0.0209\n",
            "Epoch 103: val_loss improved from 0.00040 to 0.00038, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 12ms/step - loss: 3.7270e-04 - mean_absolute_error: 0.0209 - val_loss: 3.7592e-04 - val_mean_absolute_error: 0.0198\n",
            "Epoch 104/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.6643e-04 - mean_absolute_error: 0.0207\n",
            "Epoch 104: val_loss did not improve from 0.00038\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.6647e-04 - mean_absolute_error: 0.0207 - val_loss: 3.9500e-04 - val_mean_absolute_error: 0.0204\n",
            "Epoch 105/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.6802e-04 - mean_absolute_error: 0.0207\n",
            "Epoch 105: val_loss improved from 0.00038 to 0.00037, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.6797e-04 - mean_absolute_error: 0.0207 - val_loss: 3.7329e-04 - val_mean_absolute_error: 0.0197\n",
            "Epoch 106/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.6251e-04 - mean_absolute_error: 0.0206\n",
            "Epoch 106: val_loss did not improve from 0.00037\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.6281e-04 - mean_absolute_error: 0.0206 - val_loss: 4.1940e-04 - val_mean_absolute_error: 0.0210\n",
            "Epoch 107/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.5873e-04 - mean_absolute_error: 0.0205\n",
            "Epoch 107: val_loss improved from 0.00037 to 0.00037, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.5848e-04 - mean_absolute_error: 0.0205 - val_loss: 3.6856e-04 - val_mean_absolute_error: 0.0197\n",
            "Epoch 108/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.5651e-04 - mean_absolute_error: 0.0204\n",
            "Epoch 108: val_loss did not improve from 0.00037\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.5645e-04 - mean_absolute_error: 0.0204 - val_loss: 3.8306e-04 - val_mean_absolute_error: 0.0197\n",
            "Epoch 109/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.5358e-04 - mean_absolute_error: 0.0204\n",
            "Epoch 109: val_loss did not improve from 0.00037\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.5346e-04 - mean_absolute_error: 0.0204 - val_loss: 3.7823e-04 - val_mean_absolute_error: 0.0198\n",
            "Epoch 110/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.7192e-04 - mean_absolute_error: 0.0207\n",
            "Epoch 110: val_loss did not improve from 0.00037\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.7217e-04 - mean_absolute_error: 0.0207 - val_loss: 3.9622e-04 - val_mean_absolute_error: 0.0201\n",
            "Epoch 111/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 3.4762e-04 - mean_absolute_error: 0.0202\n",
            "Epoch 111: val_loss did not improve from 0.00037\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.4762e-04 - mean_absolute_error: 0.0202 - val_loss: 3.8804e-04 - val_mean_absolute_error: 0.0197\n",
            "Epoch 112/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.5460e-04 - mean_absolute_error: 0.0203\n",
            "Epoch 112: val_loss improved from 0.00037 to 0.00036, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.5465e-04 - mean_absolute_error: 0.0203 - val_loss: 3.5807e-04 - val_mean_absolute_error: 0.0191\n",
            "Epoch 113/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 3.4410e-04 - mean_absolute_error: 0.0200\n",
            "Epoch 113: val_loss did not improve from 0.00036\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.4399e-04 - mean_absolute_error: 0.0200 - val_loss: 3.6621e-04 - val_mean_absolute_error: 0.0198\n",
            "Epoch 114/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.3993e-04 - mean_absolute_error: 0.0199\n",
            "Epoch 114: val_loss did not improve from 0.00036\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.4006e-04 - mean_absolute_error: 0.0199 - val_loss: 3.7988e-04 - val_mean_absolute_error: 0.0200\n",
            "Epoch 115/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.4209e-04 - mean_absolute_error: 0.0201\n",
            "Epoch 115: val_loss did not improve from 0.00036\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.4246e-04 - mean_absolute_error: 0.0201 - val_loss: 3.6838e-04 - val_mean_absolute_error: 0.0198\n",
            "Epoch 116/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.5111e-04 - mean_absolute_error: 0.0202\n",
            "Epoch 116: val_loss did not improve from 0.00036\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.5082e-04 - mean_absolute_error: 0.0202 - val_loss: 4.1781e-04 - val_mean_absolute_error: 0.0206\n",
            "Epoch 117/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 3.3972e-04 - mean_absolute_error: 0.0199\n",
            "Epoch 117: val_loss improved from 0.00036 to 0.00035, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.3972e-04 - mean_absolute_error: 0.0199 - val_loss: 3.5165e-04 - val_mean_absolute_error: 0.0190\n",
            "Epoch 118/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.3217e-04 - mean_absolute_error: 0.0197\n",
            "Epoch 118: val_loss did not improve from 0.00035\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.3207e-04 - mean_absolute_error: 0.0197 - val_loss: 3.8970e-04 - val_mean_absolute_error: 0.0202\n",
            "Epoch 119/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 3.3804e-04 - mean_absolute_error: 0.0199\n",
            "Epoch 119: val_loss did not improve from 0.00035\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.3804e-04 - mean_absolute_error: 0.0199 - val_loss: 3.5366e-04 - val_mean_absolute_error: 0.0187\n",
            "Epoch 120/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 3.8892e-04 - mean_absolute_error: 0.0210\n",
            "Epoch 120: val_loss did not improve from 0.00035\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.8915e-04 - mean_absolute_error: 0.0210 - val_loss: 4.4608e-04 - val_mean_absolute_error: 0.0215\n",
            "Epoch 121/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.4023e-04 - mean_absolute_error: 0.0200\n",
            "Epoch 121: val_loss did not improve from 0.00035\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.4009e-04 - mean_absolute_error: 0.0200 - val_loss: 3.9222e-04 - val_mean_absolute_error: 0.0203\n",
            "Epoch 122/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.1938e-04 - mean_absolute_error: 0.0194\n",
            "Epoch 122: val_loss did not improve from 0.00035\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.1948e-04 - mean_absolute_error: 0.0194 - val_loss: 3.6384e-04 - val_mean_absolute_error: 0.0196\n",
            "Epoch 123/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 3.2467e-04 - mean_absolute_error: 0.0195\n",
            "Epoch 123: val_loss improved from 0.00035 to 0.00033, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.2467e-04 - mean_absolute_error: 0.0195 - val_loss: 3.3350e-04 - val_mean_absolute_error: 0.0187\n",
            "Epoch 124/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.2219e-04 - mean_absolute_error: 0.0195\n",
            "Epoch 124: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.2188e-04 - mean_absolute_error: 0.0195 - val_loss: 3.3393e-04 - val_mean_absolute_error: 0.0182\n",
            "Epoch 125/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.2577e-04 - mean_absolute_error: 0.0195\n",
            "Epoch 125: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.2553e-04 - mean_absolute_error: 0.0195 - val_loss: 3.5684e-04 - val_mean_absolute_error: 0.0191\n",
            "Epoch 126/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 3.2890e-04 - mean_absolute_error: 0.0196\n",
            "Epoch 126: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.2896e-04 - mean_absolute_error: 0.0196 - val_loss: 3.7250e-04 - val_mean_absolute_error: 0.0194\n",
            "Epoch 127/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.1816e-04 - mean_absolute_error: 0.0193\n",
            "Epoch 127: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.1802e-04 - mean_absolute_error: 0.0193 - val_loss: 3.7536e-04 - val_mean_absolute_error: 0.0196\n",
            "Epoch 128/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.1650e-04 - mean_absolute_error: 0.0192\n",
            "Epoch 128: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.1633e-04 - mean_absolute_error: 0.0192 - val_loss: 3.6855e-04 - val_mean_absolute_error: 0.0195\n",
            "Epoch 129/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 3.1668e-04 - mean_absolute_error: 0.0192\n",
            "Epoch 129: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.1669e-04 - mean_absolute_error: 0.0192 - val_loss: 3.5582e-04 - val_mean_absolute_error: 0.0191\n",
            "Epoch 130/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 3.1814e-04 - mean_absolute_error: 0.0192\n",
            "Epoch 130: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.1814e-04 - mean_absolute_error: 0.0192 - val_loss: 4.1832e-04 - val_mean_absolute_error: 0.0204\n",
            "Epoch 131/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.1826e-04 - mean_absolute_error: 0.0193\n",
            "Epoch 131: val_loss improved from 0.00033 to 0.00033, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.1810e-04 - mean_absolute_error: 0.0193 - val_loss: 3.3285e-04 - val_mean_absolute_error: 0.0185\n",
            "Epoch 132/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.1032e-04 - mean_absolute_error: 0.0190\n",
            "Epoch 132: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.1048e-04 - mean_absolute_error: 0.0191 - val_loss: 3.3937e-04 - val_mean_absolute_error: 0.0185\n",
            "Epoch 133/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.1539e-04 - mean_absolute_error: 0.0192\n",
            "Epoch 133: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.1536e-04 - mean_absolute_error: 0.0192 - val_loss: 3.4246e-04 - val_mean_absolute_error: 0.0185\n",
            "Epoch 134/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.1051e-04 - mean_absolute_error: 0.0190\n",
            "Epoch 134: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.1047e-04 - mean_absolute_error: 0.0190 - val_loss: 3.6637e-04 - val_mean_absolute_error: 0.0195\n",
            "Epoch 135/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 3.1348e-04 - mean_absolute_error: 0.0191\n",
            "Epoch 135: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.1348e-04 - mean_absolute_error: 0.0191 - val_loss: 3.4060e-04 - val_mean_absolute_error: 0.0189\n",
            "Epoch 136/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.0398e-04 - mean_absolute_error: 0.0188\n",
            "Epoch 136: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.0403e-04 - mean_absolute_error: 0.0188 - val_loss: 3.3481e-04 - val_mean_absolute_error: 0.0183\n",
            "Epoch 137/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 3.0744e-04 - mean_absolute_error: 0.0190\n",
            "Epoch 137: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.0744e-04 - mean_absolute_error: 0.0190 - val_loss: 3.4731e-04 - val_mean_absolute_error: 0.0189\n",
            "Epoch 138/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 2.9836e-04 - mean_absolute_error: 0.0187\n",
            "Epoch 138: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 2.9818e-04 - mean_absolute_error: 0.0187 - val_loss: 3.5243e-04 - val_mean_absolute_error: 0.0190\n",
            "Epoch 139/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.0057e-04 - mean_absolute_error: 0.0188\n",
            "Epoch 139: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.0041e-04 - mean_absolute_error: 0.0187 - val_loss: 3.5104e-04 - val_mean_absolute_error: 0.0192\n",
            "Epoch 140/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.0869e-04 - mean_absolute_error: 0.0190\n",
            "Epoch 140: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.0856e-04 - mean_absolute_error: 0.0190 - val_loss: 3.3296e-04 - val_mean_absolute_error: 0.0182\n",
            "Epoch 141/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.9893e-04 - mean_absolute_error: 0.0187\n",
            "Epoch 141: val_loss improved from 0.00033 to 0.00033, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 2.9886e-04 - mean_absolute_error: 0.0187 - val_loss: 3.2561e-04 - val_mean_absolute_error: 0.0182\n",
            "Epoch 142/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 2.9448e-04 - mean_absolute_error: 0.0186\n",
            "Epoch 142: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.9456e-04 - mean_absolute_error: 0.0186 - val_loss: 3.6102e-04 - val_mean_absolute_error: 0.0194\n",
            "Epoch 143/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.0993e-04 - mean_absolute_error: 0.0189\n",
            "Epoch 143: val_loss improved from 0.00033 to 0.00032, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.0993e-04 - mean_absolute_error: 0.0189 - val_loss: 3.1538e-04 - val_mean_absolute_error: 0.0178\n",
            "Epoch 144/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.9593e-04 - mean_absolute_error: 0.0185\n",
            "Epoch 144: val_loss did not improve from 0.00032\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 2.9607e-04 - mean_absolute_error: 0.0185 - val_loss: 3.4609e-04 - val_mean_absolute_error: 0.0185\n",
            "Epoch 145/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.8793e-04 - mean_absolute_error: 0.0184\n",
            "Epoch 145: val_loss did not improve from 0.00032\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.8786e-04 - mean_absolute_error: 0.0184 - val_loss: 3.7562e-04 - val_mean_absolute_error: 0.0195\n",
            "Epoch 146/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.8845e-04 - mean_absolute_error: 0.0183\n",
            "Epoch 146: val_loss did not improve from 0.00032\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 2.8874e-04 - mean_absolute_error: 0.0183 - val_loss: 3.4161e-04 - val_mean_absolute_error: 0.0183\n",
            "Epoch 147/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.9355e-04 - mean_absolute_error: 0.0185\n",
            "Epoch 147: val_loss did not improve from 0.00032\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.9340e-04 - mean_absolute_error: 0.0185 - val_loss: 3.3027e-04 - val_mean_absolute_error: 0.0182\n",
            "Epoch 148/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 2.8270e-04 - mean_absolute_error: 0.0182\n",
            "Epoch 148: val_loss did not improve from 0.00032\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.8270e-04 - mean_absolute_error: 0.0182 - val_loss: 3.3704e-04 - val_mean_absolute_error: 0.0184\n",
            "Epoch 149/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 2.9939e-04 - mean_absolute_error: 0.0186\n",
            "Epoch 149: val_loss did not improve from 0.00032\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 2.9928e-04 - mean_absolute_error: 0.0186 - val_loss: 3.1583e-04 - val_mean_absolute_error: 0.0176\n",
            "Epoch 150/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 2.8486e-04 - mean_absolute_error: 0.0182\n",
            "Epoch 150: val_loss did not improve from 0.00032\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.8505e-04 - mean_absolute_error: 0.0182 - val_loss: 3.4378e-04 - val_mean_absolute_error: 0.0186\n",
            "Epoch 151/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 2.9256e-04 - mean_absolute_error: 0.0184\n",
            "Epoch 151: val_loss did not improve from 0.00032\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 2.9256e-04 - mean_absolute_error: 0.0184 - val_loss: 3.1538e-04 - val_mean_absolute_error: 0.0176\n",
            "Epoch 152/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 2.7908e-04 - mean_absolute_error: 0.0180\n",
            "Epoch 152: val_loss did not improve from 0.00032\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.7919e-04 - mean_absolute_error: 0.0180 - val_loss: 3.2123e-04 - val_mean_absolute_error: 0.0179\n",
            "Epoch 153/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.0720e-04 - mean_absolute_error: 0.0188\n",
            "Epoch 153: val_loss did not improve from 0.00032\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.0709e-04 - mean_absolute_error: 0.0188 - val_loss: 3.2293e-04 - val_mean_absolute_error: 0.0178\n",
            "Epoch 154/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.8158e-04 - mean_absolute_error: 0.0181\n",
            "Epoch 154: val_loss did not improve from 0.00032\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 2.8153e-04 - mean_absolute_error: 0.0181 - val_loss: 3.2876e-04 - val_mean_absolute_error: 0.0181\n",
            "Epoch 155/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.8502e-04 - mean_absolute_error: 0.0182\n",
            "Epoch 155: val_loss improved from 0.00032 to 0.00031, saving model to results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 2.8512e-04 - mean_absolute_error: 0.0182 - val_loss: 3.1062e-04 - val_mean_absolute_error: 0.0175\n",
            "Epoch 156/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 2.8261e-04 - mean_absolute_error: 0.0182\n",
            "Epoch 156: val_loss did not improve from 0.00031\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 2.8291e-04 - mean_absolute_error: 0.0182 - val_loss: 3.4092e-04 - val_mean_absolute_error: 0.0185\n",
            "Epoch 157/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.7940e-04 - mean_absolute_error: 0.0181\n",
            "Epoch 157: val_loss did not improve from 0.00031\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 2.7948e-04 - mean_absolute_error: 0.0181 - val_loss: 3.2113e-04 - val_mean_absolute_error: 0.0181\n",
            "loading model from results/ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "4/4 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3/3 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3/3 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3/3 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3/3 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3/3 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3/3 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3/3 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3/3 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6/6 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "3/3 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Epoch 1/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0035 - mean_absolute_error: 0.0598\n",
            "Epoch 1: val_loss improved from inf to 0.00217, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 15s 15ms/step - loss: 0.0035 - mean_absolute_error: 0.0597 - val_loss: 0.0022 - val_mean_absolute_error: 0.0458\n",
            "Epoch 2/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0028 - mean_absolute_error: 0.0536\n",
            "Epoch 2: val_loss improved from 0.00217 to 0.00209, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0028 - mean_absolute_error: 0.0536 - val_loss: 0.0021 - val_mean_absolute_error: 0.0439\n",
            "Epoch 3/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0514\n",
            "Epoch 3: val_loss improved from 0.00209 to 0.00198, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0026 - mean_absolute_error: 0.0514 - val_loss: 0.0020 - val_mean_absolute_error: 0.0434\n",
            "Epoch 4/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0497\n",
            "Epoch 4: val_loss did not improve from 0.00198\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0024 - mean_absolute_error: 0.0497 - val_loss: 0.0023 - val_mean_absolute_error: 0.0444\n",
            "Epoch 5/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0491\n",
            "Epoch 5: val_loss improved from 0.00198 to 0.00187, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0024 - mean_absolute_error: 0.0491 - val_loss: 0.0019 - val_mean_absolute_error: 0.0431\n",
            "Epoch 6/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0484\n",
            "Epoch 6: val_loss improved from 0.00187 to 0.00185, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0023 - mean_absolute_error: 0.0484 - val_loss: 0.0019 - val_mean_absolute_error: 0.0437\n",
            "Epoch 7/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0481\n",
            "Epoch 7: val_loss improved from 0.00185 to 0.00185, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0022 - mean_absolute_error: 0.0481 - val_loss: 0.0018 - val_mean_absolute_error: 0.0421\n",
            "Epoch 8/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0479\n",
            "Epoch 8: val_loss did not improve from 0.00185\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0022 - mean_absolute_error: 0.0479 - val_loss: 0.0019 - val_mean_absolute_error: 0.0434\n",
            "Epoch 9/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0477\n",
            "Epoch 9: val_loss did not improve from 0.00185\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0022 - mean_absolute_error: 0.0476 - val_loss: 0.0019 - val_mean_absolute_error: 0.0421\n",
            "Epoch 10/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0479\n",
            "Epoch 10: val_loss did not improve from 0.00185\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0022 - mean_absolute_error: 0.0479 - val_loss: 0.0019 - val_mean_absolute_error: 0.0434\n",
            "Epoch 11/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0472\n",
            "Epoch 11: val_loss improved from 0.00185 to 0.00183, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0022 - mean_absolute_error: 0.0472 - val_loss: 0.0018 - val_mean_absolute_error: 0.0428\n",
            "Epoch 12/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0472\n",
            "Epoch 12: val_loss did not improve from 0.00183\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0022 - mean_absolute_error: 0.0472 - val_loss: 0.0019 - val_mean_absolute_error: 0.0441\n",
            "Epoch 13/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0470\n",
            "Epoch 13: val_loss did not improve from 0.00183\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0021 - mean_absolute_error: 0.0470 - val_loss: 0.0020 - val_mean_absolute_error: 0.0475\n",
            "Epoch 14/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0464\n",
            "Epoch 14: val_loss improved from 0.00183 to 0.00177, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0021 - mean_absolute_error: 0.0464 - val_loss: 0.0018 - val_mean_absolute_error: 0.0423\n",
            "Epoch 15/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0463\n",
            "Epoch 15: val_loss did not improve from 0.00177\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0021 - mean_absolute_error: 0.0463 - val_loss: 0.0019 - val_mean_absolute_error: 0.0464\n",
            "Epoch 16/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0461\n",
            "Epoch 16: val_loss did not improve from 0.00177\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0021 - mean_absolute_error: 0.0461 - val_loss: 0.0018 - val_mean_absolute_error: 0.0407\n",
            "Epoch 17/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0460\n",
            "Epoch 17: val_loss improved from 0.00177 to 0.00176, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0021 - mean_absolute_error: 0.0460 - val_loss: 0.0018 - val_mean_absolute_error: 0.0419\n",
            "Epoch 18/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0458\n",
            "Epoch 18: val_loss improved from 0.00176 to 0.00175, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0020 - mean_absolute_error: 0.0458 - val_loss: 0.0018 - val_mean_absolute_error: 0.0417\n",
            "Epoch 19/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0458\n",
            "Epoch 19: val_loss did not improve from 0.00175\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0020 - mean_absolute_error: 0.0458 - val_loss: 0.0019 - val_mean_absolute_error: 0.0434\n",
            "Epoch 20/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0456\n",
            "Epoch 20: val_loss improved from 0.00175 to 0.00174, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0020 - mean_absolute_error: 0.0456 - val_loss: 0.0017 - val_mean_absolute_error: 0.0421\n",
            "Epoch 21/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0454\n",
            "Epoch 21: val_loss did not improve from 0.00174\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0020 - mean_absolute_error: 0.0454 - val_loss: 0.0018 - val_mean_absolute_error: 0.0416\n",
            "Epoch 22/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0453\n",
            "Epoch 22: val_loss did not improve from 0.00174\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0020 - mean_absolute_error: 0.0452 - val_loss: 0.0018 - val_mean_absolute_error: 0.0418\n",
            "Epoch 23/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0451\n",
            "Epoch 23: val_loss improved from 0.00174 to 0.00172, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0020 - mean_absolute_error: 0.0451 - val_loss: 0.0017 - val_mean_absolute_error: 0.0433\n",
            "Epoch 24/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0450\n",
            "Epoch 24: val_loss improved from 0.00172 to 0.00170, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0020 - mean_absolute_error: 0.0450 - val_loss: 0.0017 - val_mean_absolute_error: 0.0417\n",
            "Epoch 25/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0451\n",
            "Epoch 25: val_loss did not improve from 0.00170\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0020 - mean_absolute_error: 0.0451 - val_loss: 0.0017 - val_mean_absolute_error: 0.0410\n",
            "Epoch 26/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0447\n",
            "Epoch 26: val_loss improved from 0.00170 to 0.00168, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0019 - mean_absolute_error: 0.0447 - val_loss: 0.0017 - val_mean_absolute_error: 0.0399\n",
            "Epoch 27/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0444\n",
            "Epoch 27: val_loss improved from 0.00168 to 0.00164, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0019 - mean_absolute_error: 0.0444 - val_loss: 0.0016 - val_mean_absolute_error: 0.0398\n",
            "Epoch 28/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0441\n",
            "Epoch 28: val_loss did not improve from 0.00164\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0019 - mean_absolute_error: 0.0441 - val_loss: 0.0017 - val_mean_absolute_error: 0.0404\n",
            "Epoch 29/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0438\n",
            "Epoch 29: val_loss improved from 0.00164 to 0.00162, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0019 - mean_absolute_error: 0.0438 - val_loss: 0.0016 - val_mean_absolute_error: 0.0403\n",
            "Epoch 30/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0437\n",
            "Epoch 30: val_loss did not improve from 0.00162\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0019 - mean_absolute_error: 0.0437 - val_loss: 0.0016 - val_mean_absolute_error: 0.0413\n",
            "Epoch 31/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0436\n",
            "Epoch 31: val_loss improved from 0.00162 to 0.00161, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0018 - mean_absolute_error: 0.0436 - val_loss: 0.0016 - val_mean_absolute_error: 0.0390\n",
            "Epoch 32/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0433\n",
            "Epoch 32: val_loss did not improve from 0.00161\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0018 - mean_absolute_error: 0.0433 - val_loss: 0.0017 - val_mean_absolute_error: 0.0436\n",
            "Epoch 33/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0432\n",
            "Epoch 33: val_loss improved from 0.00161 to 0.00161, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0018 - mean_absolute_error: 0.0432 - val_loss: 0.0016 - val_mean_absolute_error: 0.0382\n",
            "Epoch 34/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0432\n",
            "Epoch 34: val_loss improved from 0.00161 to 0.00158, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0018 - mean_absolute_error: 0.0432 - val_loss: 0.0016 - val_mean_absolute_error: 0.0383\n",
            "Epoch 35/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0429\n",
            "Epoch 35: val_loss did not improve from 0.00158\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0018 - mean_absolute_error: 0.0429 - val_loss: 0.0016 - val_mean_absolute_error: 0.0422\n",
            "Epoch 36/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0425\n",
            "Epoch 36: val_loss improved from 0.00158 to 0.00153, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0018 - mean_absolute_error: 0.0425 - val_loss: 0.0015 - val_mean_absolute_error: 0.0397\n",
            "Epoch 37/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0426\n",
            "Epoch 37: val_loss improved from 0.00153 to 0.00152, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0018 - mean_absolute_error: 0.0426 - val_loss: 0.0015 - val_mean_absolute_error: 0.0372\n",
            "Epoch 38/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0420\n",
            "Epoch 38: val_loss improved from 0.00152 to 0.00152, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0017 - mean_absolute_error: 0.0420 - val_loss: 0.0015 - val_mean_absolute_error: 0.0384\n",
            "Epoch 39/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0423\n",
            "Epoch 39: val_loss improved from 0.00152 to 0.00148, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0017 - mean_absolute_error: 0.0423 - val_loss: 0.0015 - val_mean_absolute_error: 0.0381\n",
            "Epoch 40/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0417\n",
            "Epoch 40: val_loss improved from 0.00148 to 0.00147, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0017 - mean_absolute_error: 0.0417 - val_loss: 0.0015 - val_mean_absolute_error: 0.0392\n",
            "Epoch 41/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0416\n",
            "Epoch 41: val_loss did not improve from 0.00147\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0017 - mean_absolute_error: 0.0416 - val_loss: 0.0015 - val_mean_absolute_error: 0.0396\n",
            "Epoch 42/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0415\n",
            "Epoch 42: val_loss did not improve from 0.00147\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0017 - mean_absolute_error: 0.0415 - val_loss: 0.0016 - val_mean_absolute_error: 0.0378\n",
            "Epoch 43/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0409\n",
            "Epoch 43: val_loss improved from 0.00147 to 0.00147, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0016 - mean_absolute_error: 0.0409 - val_loss: 0.0015 - val_mean_absolute_error: 0.0398\n",
            "Epoch 44/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0408\n",
            "Epoch 44: val_loss improved from 0.00147 to 0.00137, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0016 - mean_absolute_error: 0.0408 - val_loss: 0.0014 - val_mean_absolute_error: 0.0360\n",
            "Epoch 45/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0406\n",
            "Epoch 45: val_loss improved from 0.00137 to 0.00135, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0016 - mean_absolute_error: 0.0406 - val_loss: 0.0013 - val_mean_absolute_error: 0.0369\n",
            "Epoch 46/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0402\n",
            "Epoch 46: val_loss improved from 0.00135 to 0.00134, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0015 - mean_absolute_error: 0.0402 - val_loss: 0.0013 - val_mean_absolute_error: 0.0385\n",
            "Epoch 47/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0400\n",
            "Epoch 47: val_loss improved from 0.00134 to 0.00130, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0015 - mean_absolute_error: 0.0400 - val_loss: 0.0013 - val_mean_absolute_error: 0.0363\n",
            "Epoch 48/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0397\n",
            "Epoch 48: val_loss improved from 0.00130 to 0.00125, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0015 - mean_absolute_error: 0.0397 - val_loss: 0.0013 - val_mean_absolute_error: 0.0358\n",
            "Epoch 49/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0393\n",
            "Epoch 49: val_loss improved from 0.00125 to 0.00122, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0015 - mean_absolute_error: 0.0393 - val_loss: 0.0012 - val_mean_absolute_error: 0.0350\n",
            "Epoch 50/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0390\n",
            "Epoch 50: val_loss did not improve from 0.00122\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0014 - mean_absolute_error: 0.0390 - val_loss: 0.0013 - val_mean_absolute_error: 0.0349\n",
            "Epoch 51/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0388\n",
            "Epoch 51: val_loss improved from 0.00122 to 0.00120, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0014 - mean_absolute_error: 0.0388 - val_loss: 0.0012 - val_mean_absolute_error: 0.0358\n",
            "Epoch 52/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0386\n",
            "Epoch 52: val_loss improved from 0.00120 to 0.00120, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0014 - mean_absolute_error: 0.0386 - val_loss: 0.0012 - val_mean_absolute_error: 0.0361\n",
            "Epoch 53/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0381\n",
            "Epoch 53: val_loss did not improve from 0.00120\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0013 - mean_absolute_error: 0.0381 - val_loss: 0.0012 - val_mean_absolute_error: 0.0360\n",
            "Epoch 54/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0378\n",
            "Epoch 54: val_loss improved from 0.00120 to 0.00110, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0013 - mean_absolute_error: 0.0378 - val_loss: 0.0011 - val_mean_absolute_error: 0.0338\n",
            "Epoch 55/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0374\n",
            "Epoch 55: val_loss did not improve from 0.00110\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0013 - mean_absolute_error: 0.0374 - val_loss: 0.0011 - val_mean_absolute_error: 0.0340\n",
            "Epoch 56/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0370\n",
            "Epoch 56: val_loss did not improve from 0.00110\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0013 - mean_absolute_error: 0.0370 - val_loss: 0.0011 - val_mean_absolute_error: 0.0331\n",
            "Epoch 57/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0367\n",
            "Epoch 57: val_loss did not improve from 0.00110\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0012 - mean_absolute_error: 0.0367 - val_loss: 0.0012 - val_mean_absolute_error: 0.0349\n",
            "Epoch 58/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0363\n",
            "Epoch 58: val_loss improved from 0.00110 to 0.00103, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0012 - mean_absolute_error: 0.0363 - val_loss: 0.0010 - val_mean_absolute_error: 0.0320\n",
            "Epoch 59/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0359\n",
            "Epoch 59: val_loss did not improve from 0.00103\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0012 - mean_absolute_error: 0.0359 - val_loss: 0.0010 - val_mean_absolute_error: 0.0332\n",
            "Epoch 60/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0359\n",
            "Epoch 60: val_loss improved from 0.00103 to 0.00100, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0012 - mean_absolute_error: 0.0359 - val_loss: 0.0010 - val_mean_absolute_error: 0.0327\n",
            "Epoch 61/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0353\n",
            "Epoch 61: val_loss did not improve from 0.00100\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0011 - mean_absolute_error: 0.0353 - val_loss: 0.0010 - val_mean_absolute_error: 0.0322\n",
            "Epoch 62/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0354\n",
            "Epoch 62: val_loss improved from 0.00100 to 0.00097, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0011 - mean_absolute_error: 0.0354 - val_loss: 9.7203e-04 - val_mean_absolute_error: 0.0319\n",
            "Epoch 63/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0346\n",
            "Epoch 63: val_loss improved from 0.00097 to 0.00094, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0011 - mean_absolute_error: 0.0346 - val_loss: 9.3901e-04 - val_mean_absolute_error: 0.0311\n",
            "Epoch 64/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0344\n",
            "Epoch 64: val_loss did not improve from 0.00094\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0011 - mean_absolute_error: 0.0344 - val_loss: 9.7050e-04 - val_mean_absolute_error: 0.0323\n",
            "Epoch 65/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0339\n",
            "Epoch 65: val_loss improved from 0.00094 to 0.00089, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0010 - mean_absolute_error: 0.0339 - val_loss: 8.9462e-04 - val_mean_absolute_error: 0.0310\n",
            "Epoch 66/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 9.9956e-04 - mean_absolute_error: 0.0332\n",
            "Epoch 66: val_loss did not improve from 0.00089\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 9.9912e-04 - mean_absolute_error: 0.0332 - val_loss: 9.3134e-04 - val_mean_absolute_error: 0.0327\n",
            "Epoch 67/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 9.6972e-04 - mean_absolute_error: 0.0329\n",
            "Epoch 67: val_loss improved from 0.00089 to 0.00082, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 9.6972e-04 - mean_absolute_error: 0.0329 - val_loss: 8.2369e-04 - val_mean_absolute_error: 0.0296\n",
            "Epoch 68/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 9.5777e-04 - mean_absolute_error: 0.0327\n",
            "Epoch 68: val_loss did not improve from 0.00082\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 9.5921e-04 - mean_absolute_error: 0.0327 - val_loss: 8.3934e-04 - val_mean_absolute_error: 0.0296\n",
            "Epoch 69/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 9.1604e-04 - mean_absolute_error: 0.0320\n",
            "Epoch 69: val_loss improved from 0.00082 to 0.00078, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 9.1533e-04 - mean_absolute_error: 0.0320 - val_loss: 7.8189e-04 - val_mean_absolute_error: 0.0294\n",
            "Epoch 70/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 8.8313e-04 - mean_absolute_error: 0.0316\n",
            "Epoch 70: val_loss improved from 0.00078 to 0.00074, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 8.8287e-04 - mean_absolute_error: 0.0316 - val_loss: 7.4185e-04 - val_mean_absolute_error: 0.0279\n",
            "Epoch 71/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 8.4972e-04 - mean_absolute_error: 0.0310\n",
            "Epoch 71: val_loss improved from 0.00074 to 0.00072, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 8.4972e-04 - mean_absolute_error: 0.0310 - val_loss: 7.2199e-04 - val_mean_absolute_error: 0.0276\n",
            "Epoch 72/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 8.3623e-04 - mean_absolute_error: 0.0308\n",
            "Epoch 72: val_loss did not improve from 0.00072\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 8.3585e-04 - mean_absolute_error: 0.0308 - val_loss: 7.2743e-04 - val_mean_absolute_error: 0.0284\n",
            "Epoch 73/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 7.8758e-04 - mean_absolute_error: 0.0300\n",
            "Epoch 73: val_loss improved from 0.00072 to 0.00068, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 7.8729e-04 - mean_absolute_error: 0.0300 - val_loss: 6.8406e-04 - val_mean_absolute_error: 0.0276\n",
            "Epoch 74/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 8.0526e-04 - mean_absolute_error: 0.0302\n",
            "Epoch 74: val_loss did not improve from 0.00068\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 8.0526e-04 - mean_absolute_error: 0.0302 - val_loss: 7.0225e-04 - val_mean_absolute_error: 0.0270\n",
            "Epoch 75/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 7.7049e-04 - mean_absolute_error: 0.0297\n",
            "Epoch 75: val_loss improved from 0.00068 to 0.00067, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 7.7012e-04 - mean_absolute_error: 0.0297 - val_loss: 6.7264e-04 - val_mean_absolute_error: 0.0271\n",
            "Epoch 76/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 7.1383e-04 - mean_absolute_error: 0.0286\n",
            "Epoch 76: val_loss improved from 0.00067 to 0.00061, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 7.1432e-04 - mean_absolute_error: 0.0287 - val_loss: 6.1498e-04 - val_mean_absolute_error: 0.0253\n",
            "Epoch 77/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 7.0143e-04 - mean_absolute_error: 0.0285\n",
            "Epoch 77: val_loss did not improve from 0.00061\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 7.0114e-04 - mean_absolute_error: 0.0285 - val_loss: 6.8001e-04 - val_mean_absolute_error: 0.0261\n",
            "Epoch 78/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 7.2399e-04 - mean_absolute_error: 0.0288\n",
            "Epoch 78: val_loss improved from 0.00061 to 0.00058, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 7.2376e-04 - mean_absolute_error: 0.0288 - val_loss: 5.7588e-04 - val_mean_absolute_error: 0.0247\n",
            "Epoch 79/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 6.5887e-04 - mean_absolute_error: 0.0276\n",
            "Epoch 79: val_loss did not improve from 0.00058\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 6.5985e-04 - mean_absolute_error: 0.0276 - val_loss: 6.2541e-04 - val_mean_absolute_error: 0.0259\n",
            "Epoch 80/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 6.5780e-04 - mean_absolute_error: 0.0276\n",
            "Epoch 80: val_loss improved from 0.00058 to 0.00053, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 6.5803e-04 - mean_absolute_error: 0.0276 - val_loss: 5.2604e-04 - val_mean_absolute_error: 0.0238\n",
            "Epoch 81/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 6.1495e-04 - mean_absolute_error: 0.0267\n",
            "Epoch 81: val_loss did not improve from 0.00053\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 6.1480e-04 - mean_absolute_error: 0.0267 - val_loss: 5.3620e-04 - val_mean_absolute_error: 0.0236\n",
            "Epoch 82/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 6.1040e-04 - mean_absolute_error: 0.0266\n",
            "Epoch 82: val_loss did not improve from 0.00053\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 6.1031e-04 - mean_absolute_error: 0.0266 - val_loss: 5.5034e-04 - val_mean_absolute_error: 0.0239\n",
            "Epoch 83/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 5.7383e-04 - mean_absolute_error: 0.0260\n",
            "Epoch 83: val_loss improved from 0.00053 to 0.00053, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 5.7395e-04 - mean_absolute_error: 0.0260 - val_loss: 5.2540e-04 - val_mean_absolute_error: 0.0238\n",
            "Epoch 84/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 5.6524e-04 - mean_absolute_error: 0.0256\n",
            "Epoch 84: val_loss improved from 0.00053 to 0.00048, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 5.6537e-04 - mean_absolute_error: 0.0256 - val_loss: 4.7756e-04 - val_mean_absolute_error: 0.0229\n",
            "Epoch 85/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 5.3989e-04 - mean_absolute_error: 0.0251\n",
            "Epoch 85: val_loss improved from 0.00048 to 0.00046, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 5.3997e-04 - mean_absolute_error: 0.0252 - val_loss: 4.6120e-04 - val_mean_absolute_error: 0.0222\n",
            "Epoch 86/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 5.5541e-04 - mean_absolute_error: 0.0253\n",
            "Epoch 86: val_loss improved from 0.00046 to 0.00044, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 5.5501e-04 - mean_absolute_error: 0.0253 - val_loss: 4.3833e-04 - val_mean_absolute_error: 0.0222\n",
            "Epoch 87/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 5.1771e-04 - mean_absolute_error: 0.0246\n",
            "Epoch 87: val_loss improved from 0.00044 to 0.00043, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 5.1809e-04 - mean_absolute_error: 0.0246 - val_loss: 4.2844e-04 - val_mean_absolute_error: 0.0219\n",
            "Epoch 88/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 5.1671e-04 - mean_absolute_error: 0.0246\n",
            "Epoch 88: val_loss did not improve from 0.00043\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 5.1660e-04 - mean_absolute_error: 0.0246 - val_loss: 4.4582e-04 - val_mean_absolute_error: 0.0217\n",
            "Epoch 89/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 4.8172e-04 - mean_absolute_error: 0.0238\n",
            "Epoch 89: val_loss did not improve from 0.00043\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 4.8172e-04 - mean_absolute_error: 0.0238 - val_loss: 4.3604e-04 - val_mean_absolute_error: 0.0215\n",
            "Epoch 90/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 4.7765e-04 - mean_absolute_error: 0.0237\n",
            "Epoch 90: val_loss improved from 0.00043 to 0.00039, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 4.7765e-04 - mean_absolute_error: 0.0237 - val_loss: 3.9255e-04 - val_mean_absolute_error: 0.0208\n",
            "Epoch 91/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 4.6240e-04 - mean_absolute_error: 0.0232\n",
            "Epoch 91: val_loss did not improve from 0.00039\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 4.6240e-04 - mean_absolute_error: 0.0232 - val_loss: 4.9936e-04 - val_mean_absolute_error: 0.0219\n",
            "Epoch 92/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 4.8414e-04 - mean_absolute_error: 0.0237\n",
            "Epoch 92: val_loss improved from 0.00039 to 0.00036, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 4.8452e-04 - mean_absolute_error: 0.0237 - val_loss: 3.5695e-04 - val_mean_absolute_error: 0.0195\n",
            "Epoch 93/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 4.5364e-04 - mean_absolute_error: 0.0229\n",
            "Epoch 93: val_loss improved from 0.00036 to 0.00035, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 4.5364e-04 - mean_absolute_error: 0.0229 - val_loss: 3.4802e-04 - val_mean_absolute_error: 0.0194\n",
            "Epoch 94/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 4.6058e-04 - mean_absolute_error: 0.0231\n",
            "Epoch 94: val_loss improved from 0.00035 to 0.00035, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 4.6042e-04 - mean_absolute_error: 0.0231 - val_loss: 3.4509e-04 - val_mean_absolute_error: 0.0192\n",
            "Epoch 95/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 4.3138e-04 - mean_absolute_error: 0.0225\n",
            "Epoch 95: val_loss did not improve from 0.00035\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 4.3138e-04 - mean_absolute_error: 0.0225 - val_loss: 3.8333e-04 - val_mean_absolute_error: 0.0203\n",
            "Epoch 96/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 4.0476e-04 - mean_absolute_error: 0.0218\n",
            "Epoch 96: val_loss improved from 0.00035 to 0.00033, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 4.0458e-04 - mean_absolute_error: 0.0218 - val_loss: 3.3278e-04 - val_mean_absolute_error: 0.0188\n",
            "Epoch 97/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 4.3448e-04 - mean_absolute_error: 0.0224\n",
            "Epoch 97: val_loss did not improve from 0.00033\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 4.3419e-04 - mean_absolute_error: 0.0224 - val_loss: 3.4954e-04 - val_mean_absolute_error: 0.0197\n",
            "Epoch 98/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 4.1539e-04 - mean_absolute_error: 0.0220\n",
            "Epoch 98: val_loss improved from 0.00033 to 0.00030, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 4.1556e-04 - mean_absolute_error: 0.0220 - val_loss: 3.0489e-04 - val_mean_absolute_error: 0.0179\n",
            "Epoch 99/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 3.9481e-04 - mean_absolute_error: 0.0215\n",
            "Epoch 99: val_loss did not improve from 0.00030\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.9481e-04 - mean_absolute_error: 0.0215 - val_loss: 3.0942e-04 - val_mean_absolute_error: 0.0182\n",
            "Epoch 100/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.8835e-04 - mean_absolute_error: 0.0213\n",
            "Epoch 100: val_loss improved from 0.00030 to 0.00029, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.8841e-04 - mean_absolute_error: 0.0213 - val_loss: 2.8670e-04 - val_mean_absolute_error: 0.0174\n",
            "Epoch 101/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.7917e-04 - mean_absolute_error: 0.0211\n",
            "Epoch 101: val_loss did not improve from 0.00029\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.7929e-04 - mean_absolute_error: 0.0211 - val_loss: 2.8853e-04 - val_mean_absolute_error: 0.0175\n",
            "Epoch 102/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.7493e-04 - mean_absolute_error: 0.0210\n",
            "Epoch 102: val_loss did not improve from 0.00029\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.7486e-04 - mean_absolute_error: 0.0210 - val_loss: 3.1368e-04 - val_mean_absolute_error: 0.0181\n",
            "Epoch 103/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.7572e-04 - mean_absolute_error: 0.0210\n",
            "Epoch 103: val_loss did not improve from 0.00029\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.7580e-04 - mean_absolute_error: 0.0210 - val_loss: 2.9505e-04 - val_mean_absolute_error: 0.0184\n",
            "Epoch 104/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 3.6628e-04 - mean_absolute_error: 0.0207\n",
            "Epoch 104: val_loss did not improve from 0.00029\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.6628e-04 - mean_absolute_error: 0.0207 - val_loss: 4.3341e-04 - val_mean_absolute_error: 0.0215\n",
            "Epoch 105/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.8423e-04 - mean_absolute_error: 0.0211\n",
            "Epoch 105: val_loss improved from 0.00029 to 0.00025, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.8403e-04 - mean_absolute_error: 0.0211 - val_loss: 2.5415e-04 - val_mean_absolute_error: 0.0164\n",
            "Epoch 106/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.3768e-04 - mean_absolute_error: 0.0199\n",
            "Epoch 106: val_loss did not improve from 0.00025\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.3811e-04 - mean_absolute_error: 0.0199 - val_loss: 2.7356e-04 - val_mean_absolute_error: 0.0172\n",
            "Epoch 107/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.4221e-04 - mean_absolute_error: 0.0200\n",
            "Epoch 107: val_loss did not improve from 0.00025\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.4230e-04 - mean_absolute_error: 0.0200 - val_loss: 2.7250e-04 - val_mean_absolute_error: 0.0170\n",
            "Epoch 108/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.5057e-04 - mean_absolute_error: 0.0202\n",
            "Epoch 108: val_loss did not improve from 0.00025\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.5041e-04 - mean_absolute_error: 0.0202 - val_loss: 2.5824e-04 - val_mean_absolute_error: 0.0168\n",
            "Epoch 109/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 3.2433e-04 - mean_absolute_error: 0.0196\n",
            "Epoch 109: val_loss did not improve from 0.00025\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.2457e-04 - mean_absolute_error: 0.0196 - val_loss: 2.6313e-04 - val_mean_absolute_error: 0.0172\n",
            "Epoch 110/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.3004e-04 - mean_absolute_error: 0.0197\n",
            "Epoch 110: val_loss improved from 0.00025 to 0.00024, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.2991e-04 - mean_absolute_error: 0.0197 - val_loss: 2.4136e-04 - val_mean_absolute_error: 0.0161\n",
            "Epoch 111/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 3.2816e-04 - mean_absolute_error: 0.0196\n",
            "Epoch 111: val_loss did not improve from 0.00024\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.2808e-04 - mean_absolute_error: 0.0196 - val_loss: 2.5893e-04 - val_mean_absolute_error: 0.0168\n",
            "Epoch 112/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 3.1569e-04 - mean_absolute_error: 0.0193\n",
            "Epoch 112: val_loss did not improve from 0.00024\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.1569e-04 - mean_absolute_error: 0.0193 - val_loss: 2.6636e-04 - val_mean_absolute_error: 0.0167\n",
            "Epoch 113/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.4156e-04 - mean_absolute_error: 0.0198\n",
            "Epoch 113: val_loss improved from 0.00024 to 0.00023, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.4147e-04 - mean_absolute_error: 0.0198 - val_loss: 2.2651e-04 - val_mean_absolute_error: 0.0156\n",
            "Epoch 114/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.1134e-04 - mean_absolute_error: 0.0191\n",
            "Epoch 114: val_loss improved from 0.00023 to 0.00023, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.1124e-04 - mean_absolute_error: 0.0191 - val_loss: 2.2649e-04 - val_mean_absolute_error: 0.0155\n",
            "Epoch 115/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 3.0549e-04 - mean_absolute_error: 0.0189\n",
            "Epoch 115: val_loss did not improve from 0.00023\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.0549e-04 - mean_absolute_error: 0.0189 - val_loss: 2.5252e-04 - val_mean_absolute_error: 0.0163\n",
            "Epoch 116/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.1651e-04 - mean_absolute_error: 0.0192\n",
            "Epoch 116: val_loss did not improve from 0.00023\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.1645e-04 - mean_absolute_error: 0.0192 - val_loss: 2.5188e-04 - val_mean_absolute_error: 0.0165\n",
            "Epoch 117/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 3.0047e-04 - mean_absolute_error: 0.0187\n",
            "Epoch 117: val_loss improved from 0.00023 to 0.00021, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.0047e-04 - mean_absolute_error: 0.0187 - val_loss: 2.1435e-04 - val_mean_absolute_error: 0.0152\n",
            "Epoch 118/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.1226e-04 - mean_absolute_error: 0.0190\n",
            "Epoch 118: val_loss improved from 0.00021 to 0.00021, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.1201e-04 - mean_absolute_error: 0.0190 - val_loss: 2.1080e-04 - val_mean_absolute_error: 0.0150\n",
            "Epoch 119/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 3.0473e-04 - mean_absolute_error: 0.0187\n",
            "Epoch 119: val_loss did not improve from 0.00021\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.0468e-04 - mean_absolute_error: 0.0187 - val_loss: 2.3585e-04 - val_mean_absolute_error: 0.0160\n",
            "Epoch 120/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 2.9266e-04 - mean_absolute_error: 0.0184\n",
            "Epoch 120: val_loss improved from 0.00021 to 0.00021, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.9275e-04 - mean_absolute_error: 0.0184 - val_loss: 2.0884e-04 - val_mean_absolute_error: 0.0145\n",
            "Epoch 121/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 2.9134e-04 - mean_absolute_error: 0.0185\n",
            "Epoch 121: val_loss did not improve from 0.00021\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.9128e-04 - mean_absolute_error: 0.0185 - val_loss: 2.2022e-04 - val_mean_absolute_error: 0.0151\n",
            "Epoch 122/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 3.1559e-04 - mean_absolute_error: 0.0190\n",
            "Epoch 122: val_loss did not improve from 0.00021\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.1554e-04 - mean_absolute_error: 0.0190 - val_loss: 2.1507e-04 - val_mean_absolute_error: 0.0152\n",
            "Epoch 123/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.8238e-04 - mean_absolute_error: 0.0181\n",
            "Epoch 123: val_loss did not improve from 0.00021\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.8241e-04 - mean_absolute_error: 0.0181 - val_loss: 2.2401e-04 - val_mean_absolute_error: 0.0156\n",
            "Epoch 124/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.8748e-04 - mean_absolute_error: 0.0183\n",
            "Epoch 124: val_loss improved from 0.00021 to 0.00021, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 2.8748e-04 - mean_absolute_error: 0.0183 - val_loss: 2.0860e-04 - val_mean_absolute_error: 0.0147\n",
            "Epoch 125/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.7801e-04 - mean_absolute_error: 0.0180\n",
            "Epoch 125: val_loss improved from 0.00021 to 0.00020, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.7793e-04 - mean_absolute_error: 0.0180 - val_loss: 2.0200e-04 - val_mean_absolute_error: 0.0146\n",
            "Epoch 126/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.7884e-04 - mean_absolute_error: 0.0180\n",
            "Epoch 126: val_loss did not improve from 0.00020\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.7881e-04 - mean_absolute_error: 0.0180 - val_loss: 2.0360e-04 - val_mean_absolute_error: 0.0145\n",
            "Epoch 127/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.7141e-04 - mean_absolute_error: 0.0178\n",
            "Epoch 127: val_loss did not improve from 0.00020\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.7134e-04 - mean_absolute_error: 0.0178 - val_loss: 2.0751e-04 - val_mean_absolute_error: 0.0149\n",
            "Epoch 128/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.8032e-04 - mean_absolute_error: 0.0180\n",
            "Epoch 128: val_loss did not improve from 0.00020\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.8038e-04 - mean_absolute_error: 0.0180 - val_loss: 2.1821e-04 - val_mean_absolute_error: 0.0152\n",
            "Epoch 129/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.8057e-04 - mean_absolute_error: 0.0180\n",
            "Epoch 129: val_loss improved from 0.00020 to 0.00020, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.8063e-04 - mean_absolute_error: 0.0180 - val_loss: 1.9942e-04 - val_mean_absolute_error: 0.0143\n",
            "Epoch 130/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 2.6193e-04 - mean_absolute_error: 0.0174\n",
            "Epoch 130: val_loss did not improve from 0.00020\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.6228e-04 - mean_absolute_error: 0.0175 - val_loss: 2.4236e-04 - val_mean_absolute_error: 0.0161\n",
            "Epoch 131/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.7144e-04 - mean_absolute_error: 0.0177\n",
            "Epoch 131: val_loss did not improve from 0.00020\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.7135e-04 - mean_absolute_error: 0.0177 - val_loss: 2.0052e-04 - val_mean_absolute_error: 0.0148\n",
            "Epoch 132/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 2.6457e-04 - mean_absolute_error: 0.0175\n",
            "Epoch 132: val_loss improved from 0.00020 to 0.00020, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.6457e-04 - mean_absolute_error: 0.0175 - val_loss: 1.9503e-04 - val_mean_absolute_error: 0.0143\n",
            "Epoch 133/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 2.6456e-04 - mean_absolute_error: 0.0175\n",
            "Epoch 133: val_loss improved from 0.00020 to 0.00018, saving model to results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 2.6472e-04 - mean_absolute_error: 0.0175 - val_loss: 1.8286e-04 - val_mean_absolute_error: 0.0138\n",
            "Epoch 134/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.6463e-04 - mean_absolute_error: 0.0175\n",
            "Epoch 134: val_loss did not improve from 0.00018\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.6471e-04 - mean_absolute_error: 0.0175 - val_loss: 1.9905e-04 - val_mean_absolute_error: 0.0146\n",
            "Epoch 135/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.6525e-04 - mean_absolute_error: 0.0175\n",
            "Epoch 135: val_loss did not improve from 0.00018\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.6518e-04 - mean_absolute_error: 0.0175 - val_loss: 1.8307e-04 - val_mean_absolute_error: 0.0141\n",
            "loading model from results/ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "4/4 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3/3 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5/5 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 0s 12ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3/3 [==============================] - 0s 10ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3/3 [==============================] - 0s 10ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3/3 [==============================] - 0s 10ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6/6 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6/6 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6/6 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3/3 [==============================] - 0s 11ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 0s 12ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3/3 [==============================] - 0s 10ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3/3 [==============================] - 0s 12ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6/6 [==============================] - 0s 10ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6/6 [==============================] - 0s 10ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3/3 [==============================] - 0s 10ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Epoch 1/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0031 - mean_absolute_error: 0.0563\n",
            "Epoch 1: val_loss improved from inf to 0.00202, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 16s 15ms/step - loss: 0.0031 - mean_absolute_error: 0.0562 - val_loss: 0.0020 - val_mean_absolute_error: 0.0451\n",
            "Epoch 2/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0504\n",
            "Epoch 2: val_loss improved from 0.00202 to 0.00197, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0025 - mean_absolute_error: 0.0504 - val_loss: 0.0020 - val_mean_absolute_error: 0.0431\n",
            "Epoch 3/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0477\n",
            "Epoch 3: val_loss improved from 0.00197 to 0.00186, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0022 - mean_absolute_error: 0.0477 - val_loss: 0.0019 - val_mean_absolute_error: 0.0450\n",
            "Epoch 4/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0463\n",
            "Epoch 4: val_loss did not improve from 0.00186\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0021 - mean_absolute_error: 0.0463 - val_loss: 0.0019 - val_mean_absolute_error: 0.0443\n",
            "Epoch 5/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0452\n",
            "Epoch 5: val_loss improved from 0.00186 to 0.00164, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0020 - mean_absolute_error: 0.0451 - val_loss: 0.0016 - val_mean_absolute_error: 0.0391\n",
            "Epoch 6/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0438\n",
            "Epoch 6: val_loss improved from 0.00164 to 0.00159, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0019 - mean_absolute_error: 0.0438 - val_loss: 0.0016 - val_mean_absolute_error: 0.0401\n",
            "Epoch 7/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0430\n",
            "Epoch 7: val_loss did not improve from 0.00159\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0018 - mean_absolute_error: 0.0430 - val_loss: 0.0018 - val_mean_absolute_error: 0.0456\n",
            "Epoch 8/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0427\n",
            "Epoch 8: val_loss improved from 0.00159 to 0.00154, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0018 - mean_absolute_error: 0.0428 - val_loss: 0.0015 - val_mean_absolute_error: 0.0406\n",
            "Epoch 9/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0420\n",
            "Epoch 9: val_loss did not improve from 0.00154\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 0.0017 - mean_absolute_error: 0.0420 - val_loss: 0.0016 - val_mean_absolute_error: 0.0384\n",
            "Epoch 10/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0418\n",
            "Epoch 10: val_loss did not improve from 0.00154\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0017 - mean_absolute_error: 0.0418 - val_loss: 0.0016 - val_mean_absolute_error: 0.0409\n",
            "Epoch 11/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0410\n",
            "Epoch 11: val_loss improved from 0.00154 to 0.00146, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0016 - mean_absolute_error: 0.0410 - val_loss: 0.0015 - val_mean_absolute_error: 0.0385\n",
            "Epoch 12/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0408\n",
            "Epoch 12: val_loss improved from 0.00146 to 0.00145, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0016 - mean_absolute_error: 0.0408 - val_loss: 0.0014 - val_mean_absolute_error: 0.0367\n",
            "Epoch 13/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0403\n",
            "Epoch 13: val_loss improved from 0.00145 to 0.00143, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0016 - mean_absolute_error: 0.0403 - val_loss: 0.0014 - val_mean_absolute_error: 0.0366\n",
            "Epoch 14/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0401\n",
            "Epoch 14: val_loss improved from 0.00143 to 0.00133, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0015 - mean_absolute_error: 0.0400 - val_loss: 0.0013 - val_mean_absolute_error: 0.0361\n",
            "Epoch 15/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0398\n",
            "Epoch 15: val_loss did not improve from 0.00133\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0015 - mean_absolute_error: 0.0398 - val_loss: 0.0014 - val_mean_absolute_error: 0.0377\n",
            "Epoch 16/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0393\n",
            "Epoch 16: val_loss improved from 0.00133 to 0.00131, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0015 - mean_absolute_error: 0.0393 - val_loss: 0.0013 - val_mean_absolute_error: 0.0354\n",
            "Epoch 17/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0391\n",
            "Epoch 17: val_loss did not improve from 0.00131\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0015 - mean_absolute_error: 0.0391 - val_loss: 0.0013 - val_mean_absolute_error: 0.0352\n",
            "Epoch 18/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0386\n",
            "Epoch 18: val_loss did not improve from 0.00131\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0014 - mean_absolute_error: 0.0386 - val_loss: 0.0014 - val_mean_absolute_error: 0.0361\n",
            "Epoch 19/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0385\n",
            "Epoch 19: val_loss did not improve from 0.00131\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0014 - mean_absolute_error: 0.0384 - val_loss: 0.0014 - val_mean_absolute_error: 0.0386\n",
            "Epoch 20/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0381\n",
            "Epoch 20: val_loss improved from 0.00131 to 0.00128, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0014 - mean_absolute_error: 0.0381 - val_loss: 0.0013 - val_mean_absolute_error: 0.0363\n",
            "Epoch 21/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0375\n",
            "Epoch 21: val_loss improved from 0.00128 to 0.00125, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0013 - mean_absolute_error: 0.0376 - val_loss: 0.0012 - val_mean_absolute_error: 0.0351\n",
            "Epoch 22/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0374\n",
            "Epoch 22: val_loss did not improve from 0.00125\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0013 - mean_absolute_error: 0.0374 - val_loss: 0.0013 - val_mean_absolute_error: 0.0366\n",
            "Epoch 23/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0366\n",
            "Epoch 23: val_loss improved from 0.00125 to 0.00111, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0013 - mean_absolute_error: 0.0366 - val_loss: 0.0011 - val_mean_absolute_error: 0.0333\n",
            "Epoch 24/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0364\n",
            "Epoch 24: val_loss did not improve from 0.00111\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0012 - mean_absolute_error: 0.0364 - val_loss: 0.0011 - val_mean_absolute_error: 0.0335\n",
            "Epoch 25/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0361\n",
            "Epoch 25: val_loss improved from 0.00111 to 0.00109, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0012 - mean_absolute_error: 0.0361 - val_loss: 0.0011 - val_mean_absolute_error: 0.0335\n",
            "Epoch 26/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0356\n",
            "Epoch 26: val_loss did not improve from 0.00109\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0012 - mean_absolute_error: 0.0356 - val_loss: 0.0011 - val_mean_absolute_error: 0.0336\n",
            "Epoch 27/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0352\n",
            "Epoch 27: val_loss improved from 0.00109 to 0.00108, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0012 - mean_absolute_error: 0.0352 - val_loss: 0.0011 - val_mean_absolute_error: 0.0331\n",
            "Epoch 28/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0350\n",
            "Epoch 28: val_loss improved from 0.00108 to 0.00102, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0011 - mean_absolute_error: 0.0350 - val_loss: 0.0010 - val_mean_absolute_error: 0.0318\n",
            "Epoch 29/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0346\n",
            "Epoch 29: val_loss improved from 0.00102 to 0.00098, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0011 - mean_absolute_error: 0.0346 - val_loss: 9.8115e-04 - val_mean_absolute_error: 0.0313\n",
            "Epoch 30/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0339\n",
            "Epoch 30: val_loss did not improve from 0.00098\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0011 - mean_absolute_error: 0.0339 - val_loss: 0.0010 - val_mean_absolute_error: 0.0322\n",
            "Epoch 31/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0337\n",
            "Epoch 31: val_loss did not improve from 0.00098\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0010 - mean_absolute_error: 0.0337 - val_loss: 0.0010 - val_mean_absolute_error: 0.0316\n",
            "Epoch 32/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0333\n",
            "Epoch 32: val_loss improved from 0.00098 to 0.00090, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 0.0010 - mean_absolute_error: 0.0333 - val_loss: 8.9625e-04 - val_mean_absolute_error: 0.0301\n",
            "Epoch 33/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0331\n",
            "Epoch 33: val_loss did not improve from 0.00090\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 0.0010 - mean_absolute_error: 0.0331 - val_loss: 9.1553e-04 - val_mean_absolute_error: 0.0308\n",
            "Epoch 34/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 9.4978e-04 - mean_absolute_error: 0.0324\n",
            "Epoch 34: val_loss did not improve from 0.00090\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 9.5030e-04 - mean_absolute_error: 0.0324 - val_loss: 9.3973e-04 - val_mean_absolute_error: 0.0307\n",
            "Epoch 35/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 9.3205e-04 - mean_absolute_error: 0.0320\n",
            "Epoch 35: val_loss improved from 0.00090 to 0.00084, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 9.3170e-04 - mean_absolute_error: 0.0320 - val_loss: 8.4037e-04 - val_mean_absolute_error: 0.0296\n",
            "Epoch 36/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 9.0180e-04 - mean_absolute_error: 0.0316\n",
            "Epoch 36: val_loss improved from 0.00084 to 0.00082, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 9.0171e-04 - mean_absolute_error: 0.0316 - val_loss: 8.1752e-04 - val_mean_absolute_error: 0.0287\n",
            "Epoch 37/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 8.7108e-04 - mean_absolute_error: 0.0311\n",
            "Epoch 37: val_loss did not improve from 0.00082\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 8.7265e-04 - mean_absolute_error: 0.0311 - val_loss: 8.5432e-04 - val_mean_absolute_error: 0.0299\n",
            "Epoch 38/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 8.5367e-04 - mean_absolute_error: 0.0309\n",
            "Epoch 38: val_loss improved from 0.00082 to 0.00081, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 8.5357e-04 - mean_absolute_error: 0.0309 - val_loss: 8.1049e-04 - val_mean_absolute_error: 0.0290\n",
            "Epoch 39/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 8.2137e-04 - mean_absolute_error: 0.0304\n",
            "Epoch 39: val_loss improved from 0.00081 to 0.00076, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 8.2117e-04 - mean_absolute_error: 0.0304 - val_loss: 7.5884e-04 - val_mean_absolute_error: 0.0281\n",
            "Epoch 40/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 7.8750e-04 - mean_absolute_error: 0.0299\n",
            "Epoch 40: val_loss improved from 0.00076 to 0.00073, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 7.8758e-04 - mean_absolute_error: 0.0299 - val_loss: 7.2999e-04 - val_mean_absolute_error: 0.0276\n",
            "Epoch 41/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 7.5432e-04 - mean_absolute_error: 0.0293\n",
            "Epoch 41: val_loss improved from 0.00073 to 0.00067, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 7.5420e-04 - mean_absolute_error: 0.0293 - val_loss: 6.7244e-04 - val_mean_absolute_error: 0.0263\n",
            "Epoch 42/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 7.5697e-04 - mean_absolute_error: 0.0294\n",
            "Epoch 42: val_loss did not improve from 0.00067\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 7.5649e-04 - mean_absolute_error: 0.0294 - val_loss: 6.8637e-04 - val_mean_absolute_error: 0.0271\n",
            "Epoch 43/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 7.3156e-04 - mean_absolute_error: 0.0289\n",
            "Epoch 43: val_loss did not improve from 0.00067\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 7.3138e-04 - mean_absolute_error: 0.0289 - val_loss: 6.9200e-04 - val_mean_absolute_error: 0.0272\n",
            "Epoch 44/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 7.0057e-04 - mean_absolute_error: 0.0283\n",
            "Epoch 44: val_loss improved from 0.00067 to 0.00066, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 7.0057e-04 - mean_absolute_error: 0.0283 - val_loss: 6.5741e-04 - val_mean_absolute_error: 0.0260\n",
            "Epoch 45/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 6.9516e-04 - mean_absolute_error: 0.0283\n",
            "Epoch 45: val_loss did not improve from 0.00066\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 6.9511e-04 - mean_absolute_error: 0.0283 - val_loss: 6.7116e-04 - val_mean_absolute_error: 0.0267\n",
            "Epoch 46/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 6.6763e-04 - mean_absolute_error: 0.0276\n",
            "Epoch 46: val_loss improved from 0.00066 to 0.00061, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 6.6763e-04 - mean_absolute_error: 0.0276 - val_loss: 6.1340e-04 - val_mean_absolute_error: 0.0255\n",
            "Epoch 47/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 6.5403e-04 - mean_absolute_error: 0.0275\n",
            "Epoch 47: val_loss did not improve from 0.00061\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 6.5433e-04 - mean_absolute_error: 0.0275 - val_loss: 6.3712e-04 - val_mean_absolute_error: 0.0262\n",
            "Epoch 48/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 6.2613e-04 - mean_absolute_error: 0.0269\n",
            "Epoch 48: val_loss improved from 0.00061 to 0.00059, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 6.2615e-04 - mean_absolute_error: 0.0269 - val_loss: 5.9265e-04 - val_mean_absolute_error: 0.0256\n",
            "Epoch 49/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 6.1564e-04 - mean_absolute_error: 0.0267\n",
            "Epoch 49: val_loss improved from 0.00059 to 0.00055, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 6.1548e-04 - mean_absolute_error: 0.0267 - val_loss: 5.4514e-04 - val_mean_absolute_error: 0.0236\n",
            "Epoch 50/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 6.0690e-04 - mean_absolute_error: 0.0265\n",
            "Epoch 50: val_loss did not improve from 0.00055\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 6.0701e-04 - mean_absolute_error: 0.0265 - val_loss: 5.7352e-04 - val_mean_absolute_error: 0.0248\n",
            "Epoch 51/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 5.7582e-04 - mean_absolute_error: 0.0259\n",
            "Epoch 51: val_loss improved from 0.00055 to 0.00052, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 5.7565e-04 - mean_absolute_error: 0.0259 - val_loss: 5.1865e-04 - val_mean_absolute_error: 0.0233\n",
            "Epoch 52/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 5.5604e-04 - mean_absolute_error: 0.0255\n",
            "Epoch 52: val_loss improved from 0.00052 to 0.00050, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 5.5611e-04 - mean_absolute_error: 0.0255 - val_loss: 5.0296e-04 - val_mean_absolute_error: 0.0228\n",
            "Epoch 53/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 5.3857e-04 - mean_absolute_error: 0.0251\n",
            "Epoch 53: val_loss improved from 0.00050 to 0.00049, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 5.3813e-04 - mean_absolute_error: 0.0251 - val_loss: 4.8612e-04 - val_mean_absolute_error: 0.0226\n",
            "Epoch 54/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 5.2898e-04 - mean_absolute_error: 0.0248\n",
            "Epoch 54: val_loss did not improve from 0.00049\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 5.2903e-04 - mean_absolute_error: 0.0248 - val_loss: 5.0021e-04 - val_mean_absolute_error: 0.0238\n",
            "Epoch 55/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 5.1176e-04 - mean_absolute_error: 0.0245\n",
            "Epoch 55: val_loss improved from 0.00049 to 0.00046, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 5.1205e-04 - mean_absolute_error: 0.0245 - val_loss: 4.6056e-04 - val_mean_absolute_error: 0.0224\n",
            "Epoch 56/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 5.0683e-04 - mean_absolute_error: 0.0244\n",
            "Epoch 56: val_loss improved from 0.00046 to 0.00043, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 5.0666e-04 - mean_absolute_error: 0.0244 - val_loss: 4.2584e-04 - val_mean_absolute_error: 0.0211\n",
            "Epoch 57/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 4.9031e-04 - mean_absolute_error: 0.0240\n",
            "Epoch 57: val_loss improved from 0.00043 to 0.00042, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 4.9014e-04 - mean_absolute_error: 0.0240 - val_loss: 4.2045e-04 - val_mean_absolute_error: 0.0211\n",
            "Epoch 58/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 4.6767e-04 - mean_absolute_error: 0.0235\n",
            "Epoch 58: val_loss did not improve from 0.00042\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 4.6755e-04 - mean_absolute_error: 0.0235 - val_loss: 4.3168e-04 - val_mean_absolute_error: 0.0212\n",
            "Epoch 59/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 4.6027e-04 - mean_absolute_error: 0.0233\n",
            "Epoch 59: val_loss improved from 0.00042 to 0.00040, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 4.6027e-04 - mean_absolute_error: 0.0233 - val_loss: 4.0267e-04 - val_mean_absolute_error: 0.0206\n",
            "Epoch 60/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 4.4457e-04 - mean_absolute_error: 0.0229\n",
            "Epoch 60: val_loss did not improve from 0.00040\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 4.4467e-04 - mean_absolute_error: 0.0229 - val_loss: 4.0349e-04 - val_mean_absolute_error: 0.0208\n",
            "Epoch 61/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 4.3813e-04 - mean_absolute_error: 0.0227\n",
            "Epoch 61: val_loss improved from 0.00040 to 0.00039, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 4.3815e-04 - mean_absolute_error: 0.0227 - val_loss: 3.8735e-04 - val_mean_absolute_error: 0.0205\n",
            "Epoch 62/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 4.2655e-04 - mean_absolute_error: 0.0224\n",
            "Epoch 62: val_loss did not improve from 0.00039\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 4.2674e-04 - mean_absolute_error: 0.0224 - val_loss: 3.9679e-04 - val_mean_absolute_error: 0.0207\n",
            "Epoch 63/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 4.1286e-04 - mean_absolute_error: 0.0221\n",
            "Epoch 63: val_loss did not improve from 0.00039\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 4.1275e-04 - mean_absolute_error: 0.0221 - val_loss: 4.1575e-04 - val_mean_absolute_error: 0.0212\n",
            "Epoch 64/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.9571e-04 - mean_absolute_error: 0.0216\n",
            "Epoch 64: val_loss improved from 0.00039 to 0.00034, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.9530e-04 - mean_absolute_error: 0.0216 - val_loss: 3.4231e-04 - val_mean_absolute_error: 0.0190\n",
            "Epoch 65/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.8628e-04 - mean_absolute_error: 0.0213\n",
            "Epoch 65: val_loss did not improve from 0.00034\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.8627e-04 - mean_absolute_error: 0.0214 - val_loss: 3.6364e-04 - val_mean_absolute_error: 0.0193\n",
            "Epoch 66/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 3.7982e-04 - mean_absolute_error: 0.0211\n",
            "Epoch 66: val_loss improved from 0.00034 to 0.00034, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.7982e-04 - mean_absolute_error: 0.0211 - val_loss: 3.3905e-04 - val_mean_absolute_error: 0.0188\n",
            "Epoch 67/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 3.6961e-04 - mean_absolute_error: 0.0209\n",
            "Epoch 67: val_loss did not improve from 0.00034\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.6961e-04 - mean_absolute_error: 0.0209 - val_loss: 3.4614e-04 - val_mean_absolute_error: 0.0190\n",
            "Epoch 68/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.6269e-04 - mean_absolute_error: 0.0207\n",
            "Epoch 68: val_loss improved from 0.00034 to 0.00032, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.6317e-04 - mean_absolute_error: 0.0207 - val_loss: 3.2223e-04 - val_mean_absolute_error: 0.0186\n",
            "Epoch 69/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.5972e-04 - mean_absolute_error: 0.0206\n",
            "Epoch 69: val_loss improved from 0.00032 to 0.00031, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.5992e-04 - mean_absolute_error: 0.0206 - val_loss: 3.1354e-04 - val_mean_absolute_error: 0.0181\n",
            "Epoch 70/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.4623e-04 - mean_absolute_error: 0.0203\n",
            "Epoch 70: val_loss did not improve from 0.00031\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.4614e-04 - mean_absolute_error: 0.0203 - val_loss: 3.2055e-04 - val_mean_absolute_error: 0.0183\n",
            "Epoch 71/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 3.4224e-04 - mean_absolute_error: 0.0201\n",
            "Epoch 71: val_loss improved from 0.00031 to 0.00031, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.4209e-04 - mean_absolute_error: 0.0201 - val_loss: 3.0810e-04 - val_mean_absolute_error: 0.0179\n",
            "Epoch 72/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 3.2931e-04 - mean_absolute_error: 0.0198\n",
            "Epoch 72: val_loss improved from 0.00031 to 0.00029, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.2931e-04 - mean_absolute_error: 0.0198 - val_loss: 2.8923e-04 - val_mean_absolute_error: 0.0173\n",
            "Epoch 73/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.2917e-04 - mean_absolute_error: 0.0197\n",
            "Epoch 73: val_loss did not improve from 0.00029\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.2926e-04 - mean_absolute_error: 0.0197 - val_loss: 2.9201e-04 - val_mean_absolute_error: 0.0174\n",
            "Epoch 74/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 3.2370e-04 - mean_absolute_error: 0.0195\n",
            "Epoch 74: val_loss did not improve from 0.00029\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.2377e-04 - mean_absolute_error: 0.0195 - val_loss: 2.9310e-04 - val_mean_absolute_error: 0.0173\n",
            "Epoch 75/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 3.2290e-04 - mean_absolute_error: 0.0195\n",
            "Epoch 75: val_loss improved from 0.00029 to 0.00027, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 3.2293e-04 - mean_absolute_error: 0.0195 - val_loss: 2.7269e-04 - val_mean_absolute_error: 0.0168\n",
            "Epoch 76/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 3.1248e-04 - mean_absolute_error: 0.0192\n",
            "Epoch 76: val_loss did not improve from 0.00027\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 3.1248e-04 - mean_absolute_error: 0.0192 - val_loss: 4.0854e-04 - val_mean_absolute_error: 0.0205\n",
            "Epoch 77/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 3.0958e-04 - mean_absolute_error: 0.0190\n",
            "Epoch 77: val_loss improved from 0.00027 to 0.00024, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 3.0958e-04 - mean_absolute_error: 0.0190 - val_loss: 2.4399e-04 - val_mean_absolute_error: 0.0158\n",
            "Epoch 78/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.9756e-04 - mean_absolute_error: 0.0187\n",
            "Epoch 78: val_loss improved from 0.00024 to 0.00024, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 11s 14ms/step - loss: 2.9746e-04 - mean_absolute_error: 0.0187 - val_loss: 2.4269e-04 - val_mean_absolute_error: 0.0157\n",
            "Epoch 79/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.9394e-04 - mean_absolute_error: 0.0186\n",
            "Epoch 79: val_loss did not improve from 0.00024\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.9387e-04 - mean_absolute_error: 0.0186 - val_loss: 2.9011e-04 - val_mean_absolute_error: 0.0174\n",
            "Epoch 80/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 2.9052e-04 - mean_absolute_error: 0.0185\n",
            "Epoch 80: val_loss did not improve from 0.00024\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 2.9058e-04 - mean_absolute_error: 0.0185 - val_loss: 2.4471e-04 - val_mean_absolute_error: 0.0159\n",
            "Epoch 81/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.8330e-04 - mean_absolute_error: 0.0183\n",
            "Epoch 81: val_loss did not improve from 0.00024\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.8327e-04 - mean_absolute_error: 0.0183 - val_loss: 2.5448e-04 - val_mean_absolute_error: 0.0163\n",
            "Epoch 82/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.8131e-04 - mean_absolute_error: 0.0182\n",
            "Epoch 82: val_loss did not improve from 0.00024\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.8139e-04 - mean_absolute_error: 0.0182 - val_loss: 2.4963e-04 - val_mean_absolute_error: 0.0160\n",
            "Epoch 83/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.8053e-04 - mean_absolute_error: 0.0182\n",
            "Epoch 83: val_loss did not improve from 0.00024\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.8081e-04 - mean_absolute_error: 0.0182 - val_loss: 2.4817e-04 - val_mean_absolute_error: 0.0158\n",
            "Epoch 84/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 2.7534e-04 - mean_absolute_error: 0.0180\n",
            "Epoch 84: val_loss improved from 0.00024 to 0.00023, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.7534e-04 - mean_absolute_error: 0.0180 - val_loss: 2.2986e-04 - val_mean_absolute_error: 0.0154\n",
            "Epoch 85/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.8142e-04 - mean_absolute_error: 0.0181\n",
            "Epoch 85: val_loss did not improve from 0.00023\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.8134e-04 - mean_absolute_error: 0.0181 - val_loss: 2.3866e-04 - val_mean_absolute_error: 0.0156\n",
            "Epoch 86/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 2.6450e-04 - mean_absolute_error: 0.0177\n",
            "Epoch 86: val_loss improved from 0.00023 to 0.00023, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.6458e-04 - mean_absolute_error: 0.0177 - val_loss: 2.2698e-04 - val_mean_absolute_error: 0.0151\n",
            "Epoch 87/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.6175e-04 - mean_absolute_error: 0.0175\n",
            "Epoch 87: val_loss improved from 0.00023 to 0.00022, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.6171e-04 - mean_absolute_error: 0.0175 - val_loss: 2.2036e-04 - val_mean_absolute_error: 0.0149\n",
            "Epoch 88/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.6203e-04 - mean_absolute_error: 0.0175\n",
            "Epoch 88: val_loss did not improve from 0.00022\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.6191e-04 - mean_absolute_error: 0.0175 - val_loss: 2.4685e-04 - val_mean_absolute_error: 0.0161\n",
            "Epoch 89/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 2.5782e-04 - mean_absolute_error: 0.0174\n",
            "Epoch 89: val_loss improved from 0.00022 to 0.00021, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.5811e-04 - mean_absolute_error: 0.0174 - val_loss: 2.0925e-04 - val_mean_absolute_error: 0.0145\n",
            "Epoch 90/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.5452e-04 - mean_absolute_error: 0.0173\n",
            "Epoch 90: val_loss did not improve from 0.00021\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.5448e-04 - mean_absolute_error: 0.0173 - val_loss: 2.4383e-04 - val_mean_absolute_error: 0.0156\n",
            "Epoch 91/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 2.5407e-04 - mean_absolute_error: 0.0172\n",
            "Epoch 91: val_loss did not improve from 0.00021\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.5409e-04 - mean_absolute_error: 0.0172 - val_loss: 2.1679e-04 - val_mean_absolute_error: 0.0147\n",
            "Epoch 92/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.4978e-04 - mean_absolute_error: 0.0171\n",
            "Epoch 92: val_loss did not improve from 0.00021\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.4978e-04 - mean_absolute_error: 0.0171 - val_loss: 2.1013e-04 - val_mean_absolute_error: 0.0146\n",
            "Epoch 93/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 2.4395e-04 - mean_absolute_error: 0.0169\n",
            "Epoch 93: val_loss improved from 0.00021 to 0.00020, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.4379e-04 - mean_absolute_error: 0.0169 - val_loss: 2.0290e-04 - val_mean_absolute_error: 0.0142\n",
            "Epoch 94/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.4361e-04 - mean_absolute_error: 0.0169\n",
            "Epoch 94: val_loss improved from 0.00020 to 0.00020, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.4373e-04 - mean_absolute_error: 0.0169 - val_loss: 1.9949e-04 - val_mean_absolute_error: 0.0140\n",
            "Epoch 95/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 2.3916e-04 - mean_absolute_error: 0.0167\n",
            "Epoch 95: val_loss did not improve from 0.00020\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.3938e-04 - mean_absolute_error: 0.0167 - val_loss: 2.0614e-04 - val_mean_absolute_error: 0.0142\n",
            "Epoch 96/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 2.3806e-04 - mean_absolute_error: 0.0167\n",
            "Epoch 96: val_loss did not improve from 0.00020\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.3792e-04 - mean_absolute_error: 0.0167 - val_loss: 2.0033e-04 - val_mean_absolute_error: 0.0140\n",
            "Epoch 97/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.3367e-04 - mean_absolute_error: 0.0165\n",
            "Epoch 97: val_loss did not improve from 0.00020\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.3361e-04 - mean_absolute_error: 0.0165 - val_loss: 2.0938e-04 - val_mean_absolute_error: 0.0146\n",
            "Epoch 98/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.3325e-04 - mean_absolute_error: 0.0165\n",
            "Epoch 98: val_loss did not improve from 0.00020\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.3334e-04 - mean_absolute_error: 0.0165 - val_loss: 2.0473e-04 - val_mean_absolute_error: 0.0143\n",
            "Epoch 99/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 2.3355e-04 - mean_absolute_error: 0.0165\n",
            "Epoch 99: val_loss did not improve from 0.00020\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.3358e-04 - mean_absolute_error: 0.0165 - val_loss: 2.0753e-04 - val_mean_absolute_error: 0.0144\n",
            "Epoch 100/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 2.3180e-04 - mean_absolute_error: 0.0164\n",
            "Epoch 100: val_loss did not improve from 0.00020\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.3190e-04 - mean_absolute_error: 0.0164 - val_loss: 2.0574e-04 - val_mean_absolute_error: 0.0144\n",
            "Epoch 101/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 2.2540e-04 - mean_absolute_error: 0.0161\n",
            "Epoch 101: val_loss did not improve from 0.00020\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.2574e-04 - mean_absolute_error: 0.0161 - val_loss: 2.0438e-04 - val_mean_absolute_error: 0.0142\n",
            "Epoch 102/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.2520e-04 - mean_absolute_error: 0.0162\n",
            "Epoch 102: val_loss improved from 0.00020 to 0.00020, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.2531e-04 - mean_absolute_error: 0.0162 - val_loss: 1.9530e-04 - val_mean_absolute_error: 0.0140\n",
            "Epoch 103/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 2.2614e-04 - mean_absolute_error: 0.0162\n",
            "Epoch 103: val_loss improved from 0.00020 to 0.00019, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.2598e-04 - mean_absolute_error: 0.0162 - val_loss: 1.8675e-04 - val_mean_absolute_error: 0.0137\n",
            "Epoch 104/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.1949e-04 - mean_absolute_error: 0.0159\n",
            "Epoch 104: val_loss did not improve from 0.00019\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.1954e-04 - mean_absolute_error: 0.0159 - val_loss: 2.0010e-04 - val_mean_absolute_error: 0.0139\n",
            "Epoch 105/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 2.2265e-04 - mean_absolute_error: 0.0161\n",
            "Epoch 105: val_loss improved from 0.00019 to 0.00018, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.2251e-04 - mean_absolute_error: 0.0161 - val_loss: 1.7889e-04 - val_mean_absolute_error: 0.0132\n",
            "Epoch 106/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 2.1571e-04 - mean_absolute_error: 0.0158\n",
            "Epoch 106: val_loss did not improve from 0.00018\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.1579e-04 - mean_absolute_error: 0.0158 - val_loss: 1.9335e-04 - val_mean_absolute_error: 0.0138\n",
            "Epoch 107/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 2.1865e-04 - mean_absolute_error: 0.0159\n",
            "Epoch 107: val_loss did not improve from 0.00018\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.1849e-04 - mean_absolute_error: 0.0159 - val_loss: 1.8539e-04 - val_mean_absolute_error: 0.0134\n",
            "Epoch 108/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 2.1302e-04 - mean_absolute_error: 0.0157\n",
            "Epoch 108: val_loss did not improve from 0.00018\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.1309e-04 - mean_absolute_error: 0.0157 - val_loss: 1.9016e-04 - val_mean_absolute_error: 0.0139\n",
            "Epoch 109/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.1237e-04 - mean_absolute_error: 0.0157\n",
            "Epoch 109: val_loss improved from 0.00018 to 0.00017, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.1231e-04 - mean_absolute_error: 0.0157 - val_loss: 1.6752e-04 - val_mean_absolute_error: 0.0127\n",
            "Epoch 110/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 2.1475e-04 - mean_absolute_error: 0.0157\n",
            "Epoch 110: val_loss did not improve from 0.00017\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.1476e-04 - mean_absolute_error: 0.0157 - val_loss: 1.7929e-04 - val_mean_absolute_error: 0.0132\n",
            "Epoch 111/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 2.1048e-04 - mean_absolute_error: 0.0156\n",
            "Epoch 111: val_loss did not improve from 0.00017\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.1052e-04 - mean_absolute_error: 0.0156 - val_loss: 1.8917e-04 - val_mean_absolute_error: 0.0140\n",
            "Epoch 112/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.1087e-04 - mean_absolute_error: 0.0156\n",
            "Epoch 112: val_loss did not improve from 0.00017\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.1085e-04 - mean_absolute_error: 0.0156 - val_loss: 1.7590e-04 - val_mean_absolute_error: 0.0130\n",
            "Epoch 113/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.0868e-04 - mean_absolute_error: 0.0155\n",
            "Epoch 113: val_loss did not improve from 0.00017\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 2.0862e-04 - mean_absolute_error: 0.0155 - val_loss: 1.9850e-04 - val_mean_absolute_error: 0.0143\n",
            "Epoch 114/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 2.0406e-04 - mean_absolute_error: 0.0153\n",
            "Epoch 114: val_loss did not improve from 0.00017\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 2.0408e-04 - mean_absolute_error: 0.0153 - val_loss: 1.6776e-04 - val_mean_absolute_error: 0.0125\n",
            "Epoch 115/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 2.0751e-04 - mean_absolute_error: 0.0155\n",
            "Epoch 115: val_loss improved from 0.00017 to 0.00017, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.0758e-04 - mean_absolute_error: 0.0155 - val_loss: 1.6697e-04 - val_mean_absolute_error: 0.0125\n",
            "Epoch 116/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 2.0054e-04 - mean_absolute_error: 0.0152\n",
            "Epoch 116: val_loss did not improve from 0.00017\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.0054e-04 - mean_absolute_error: 0.0152 - val_loss: 1.7086e-04 - val_mean_absolute_error: 0.0127\n",
            "Epoch 117/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 2.0015e-04 - mean_absolute_error: 0.0152\n",
            "Epoch 117: val_loss improved from 0.00017 to 0.00016, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 2.0034e-04 - mean_absolute_error: 0.0152 - val_loss: 1.5853e-04 - val_mean_absolute_error: 0.0122\n",
            "Epoch 118/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 1.9647e-04 - mean_absolute_error: 0.0151\n",
            "Epoch 118: val_loss did not improve from 0.00016\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 1.9644e-04 - mean_absolute_error: 0.0151 - val_loss: 1.6684e-04 - val_mean_absolute_error: 0.0126\n",
            "Epoch 119/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 1.9857e-04 - mean_absolute_error: 0.0151\n",
            "Epoch 119: val_loss did not improve from 0.00016\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 1.9872e-04 - mean_absolute_error: 0.0151 - val_loss: 1.7893e-04 - val_mean_absolute_error: 0.0134\n",
            "Epoch 120/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 1.9841e-04 - mean_absolute_error: 0.0152\n",
            "Epoch 120: val_loss did not improve from 0.00016\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 1.9867e-04 - mean_absolute_error: 0.0152 - val_loss: 1.6088e-04 - val_mean_absolute_error: 0.0122\n",
            "Epoch 121/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 1.9829e-04 - mean_absolute_error: 0.0151\n",
            "Epoch 121: val_loss did not improve from 0.00016\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 1.9832e-04 - mean_absolute_error: 0.0151 - val_loss: 1.6034e-04 - val_mean_absolute_error: 0.0122\n",
            "Epoch 122/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 1.9270e-04 - mean_absolute_error: 0.0149\n",
            "Epoch 122: val_loss improved from 0.00016 to 0.00015, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 1.9276e-04 - mean_absolute_error: 0.0149 - val_loss: 1.5200e-04 - val_mean_absolute_error: 0.0118\n",
            "Epoch 123/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 1.9199e-04 - mean_absolute_error: 0.0149\n",
            "Epoch 123: val_loss did not improve from 0.00015\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 1.9199e-04 - mean_absolute_error: 0.0149 - val_loss: 1.6581e-04 - val_mean_absolute_error: 0.0127\n",
            "Epoch 124/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 1.9011e-04 - mean_absolute_error: 0.0148\n",
            "Epoch 124: val_loss did not improve from 0.00015\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 1.9004e-04 - mean_absolute_error: 0.0148 - val_loss: 1.6305e-04 - val_mean_absolute_error: 0.0122\n",
            "Epoch 125/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 1.8862e-04 - mean_absolute_error: 0.0147\n",
            "Epoch 125: val_loss did not improve from 0.00015\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 1.8870e-04 - mean_absolute_error: 0.0147 - val_loss: 1.6636e-04 - val_mean_absolute_error: 0.0128\n",
            "Epoch 126/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 1.9079e-04 - mean_absolute_error: 0.0148\n",
            "Epoch 126: val_loss did not improve from 0.00015\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 1.9070e-04 - mean_absolute_error: 0.0148 - val_loss: 1.5804e-04 - val_mean_absolute_error: 0.0122\n",
            "Epoch 127/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 1.9046e-04 - mean_absolute_error: 0.0147\n",
            "Epoch 127: val_loss did not improve from 0.00015\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 1.9053e-04 - mean_absolute_error: 0.0147 - val_loss: 1.6325e-04 - val_mean_absolute_error: 0.0125\n",
            "Epoch 128/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 1.8814e-04 - mean_absolute_error: 0.0147\n",
            "Epoch 128: val_loss did not improve from 0.00015\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 1.8822e-04 - mean_absolute_error: 0.0147 - val_loss: 1.5898e-04 - val_mean_absolute_error: 0.0121\n",
            "Epoch 129/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 1.8990e-04 - mean_absolute_error: 0.0147\n",
            "Epoch 129: val_loss did not improve from 0.00015\n",
            "729/729 [==============================] - 9s 13ms/step - loss: 1.8992e-04 - mean_absolute_error: 0.0147 - val_loss: 1.6244e-04 - val_mean_absolute_error: 0.0122\n",
            "Epoch 130/200\n",
            "728/729 [============================>.] - ETA: 0s - loss: 1.8457e-04 - mean_absolute_error: 0.0146\n",
            "Epoch 130: val_loss did not improve from 0.00015\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 1.8457e-04 - mean_absolute_error: 0.0146 - val_loss: 1.5291e-04 - val_mean_absolute_error: 0.0122\n",
            "Epoch 131/200\n",
            "727/729 [============================>.] - ETA: 0s - loss: 1.8312e-04 - mean_absolute_error: 0.0145\n",
            "Epoch 131: val_loss did not improve from 0.00015\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 1.8323e-04 - mean_absolute_error: 0.0145 - val_loss: 1.5772e-04 - val_mean_absolute_error: 0.0121\n",
            "Epoch 132/200\n",
            "729/729 [==============================] - ETA: 0s - loss: 1.8383e-04 - mean_absolute_error: 0.0145\n",
            "Epoch 132: val_loss improved from 0.00015 to 0.00014, saving model to results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 1.8383e-04 - mean_absolute_error: 0.0145 - val_loss: 1.4493e-04 - val_mean_absolute_error: 0.0115\n",
            "Epoch 133/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 1.8738e-04 - mean_absolute_error: 0.0146\n",
            "Epoch 133: val_loss did not improve from 0.00014\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 1.8736e-04 - mean_absolute_error: 0.0146 - val_loss: 1.6435e-04 - val_mean_absolute_error: 0.0124\n",
            "Epoch 134/200\n",
            "726/729 [============================>.] - ETA: 0s - loss: 1.8528e-04 - mean_absolute_error: 0.0146\n",
            "Epoch 134: val_loss did not improve from 0.00014\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 1.8532e-04 - mean_absolute_error: 0.0146 - val_loss: 1.5400e-04 - val_mean_absolute_error: 0.0123\n",
            "Epoch 135/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 1.8348e-04 - mean_absolute_error: 0.0144\n",
            "Epoch 135: val_loss did not improve from 0.00014\n",
            "729/729 [==============================] - 10s 13ms/step - loss: 1.8346e-04 - mean_absolute_error: 0.0144 - val_loss: 1.4830e-04 - val_mean_absolute_error: 0.0117\n",
            "Epoch 136/200\n",
            "725/729 [============================>.] - ETA: 0s - loss: 1.8373e-04 - mean_absolute_error: 0.0145\n",
            "Epoch 136: val_loss did not improve from 0.00014\n",
            "729/729 [==============================] - 10s 14ms/step - loss: 1.8357e-04 - mean_absolute_error: 0.0145 - val_loss: 1.6389e-04 - val_mean_absolute_error: 0.0131\n",
            "loading model from results/ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "4/4 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3/3 [==============================] - 0s 10ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5/5 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3/3 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3/3 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3/3 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3/3 [==============================] - 0s 11ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5/5 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3/3 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "6/6 [==============================] - 0s 10ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3/3 [==============================] - 0s 11ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3/3 [==============================] - 0s 12ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 0s 12ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3/3 [==============================] - 0s 11ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6/6 [==============================] - 0s 10ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6/6 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6/6 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6/6 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7e0d3c11c63b>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                          \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                          ]))\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdf\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunModelCombinedVola\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtickers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ipos2-3a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlossfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ],
      "source": [
        "findata.EPOCHS=200\n",
        "pipeline.IS_VERBOSE = False\n",
        "pending = ['PAR']\n",
        "tickers = ['ABNB', 'ACLS' ,'AI', 'AMBA', 'APP',\n",
        "           'BILL', 'BMBL', 'CELH', 'CFLT', 'CHGG', 'CRCT', 'CRWD',\n",
        "           'DASH', 'DBX', 'DDOG', 'DOCN', 'DOCS', 'DOCU', 'DXCM',\n",
        "           'ESTC', 'ETSY', 'EXPE', 'FOUR', 'GFS', 'GLBE', 'GOGO',\n",
        "           'INDI', 'INMD', 'INTA', 'IOT','JKS', 'LUMN', 'LYFT',\n",
        "           'MAXR', 'MBLY', 'MDB',  'MNDY', 'MNST', 'MPWR',  'MXL',\n",
        "           'MTCH',  'NVCR','OKTA', 'OLED', 'OSTK',\n",
        "           'PANW', 'PAYO', 'PD', 'PLUG', 'PI', 'PINS', 'PTON', 'PUBM', 'RBLX',\n",
        "           'SNAP', 'SNOW', 'SPLK', 'SPOT','STEM', 'STNE','SWAV',\n",
        "           'TEAM', 'TDOC', 'TOST', 'TTD', 'TWLO',\n",
        "           'U','UI', 'UBER', 'UPWK', 'WOLF', 'VEEV', 'Z', 'ZM', 'ZS']\n",
        "lossfn = \"huber_loss\"\n",
        "mod = pipeline.RateReturnOnly(\n",
        "    pipeline.FeatureSeq([pipeline.AddDayMonth(),\n",
        "                         pipeline.AddVWap(),\n",
        "                         pipeline.AddMA(200),\n",
        "                         pipeline.Adj()\n",
        "                         ]))\n",
        "df  = pipeline.runModelCombinedVola(tickers, 'ipos2-3a', mod, True, loss=lossfn)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lUUYXO9xMty"
      },
      "outputs": [],
      "source": [
        "data = pipeline.fetch_data('Z')\n",
        "data = data.tail(1000)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sw99bVXNIEym"
      },
      "outputs": [],
      "source": [
        "display(df.sort_values('Gain', ascending=False))\n",
        "display(df[[\"Buy\", \"Sell\", \"Total\"]].sum()/len(df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8YUKnIIxMtz"
      },
      "outputs": [],
      "source": [
        "results['ABNB'].pdata.__dict__.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f5Ns68gHHpf"
      },
      "outputs": [],
      "source": [
        "findata.EPOCHS=10\n",
        "tickers1 = ['ARKK', 'ARKW', 'DAPP', 'DTEC', 'EEM', 'FPX',\n",
        "            'GBTC', 'GLD',\n",
        "            'ICLN', 'IJR', 'IPO', 'IPOS', 'IWM',\n",
        "            'JETS', 'KEMQ',\n",
        "            'MGK', 'MGV', 'MOAT', 'MTUM',\n",
        "            'QQQ', 'SLV','SMH', 'SMOG',\n",
        "            'SPY', 'VNQ', 'VT', 'VTI', 'WDIV',\n",
        "            'XLB', 'XLC', 'XLE', 'XLF', 'XLI', 'XLK',\n",
        "            'XLRE', 'XLU', 'XLV', 'XLY', 'XME' ]\n",
        "mod = pipeline.RateReturnOnly(pipeline.FeatureSeq([pipeline.AddDayMonth(), pipeline.AddVWap()]))\n",
        "df1 = pipeline.runModelCombined(tickers1, 'etf2b', mod, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0wy3LeuIMg7"
      },
      "outputs": [],
      "source": [
        "df1.sort_values('Gain', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8wpIWG5xMt0"
      },
      "outputs": [],
      "source": [
        "findata.EPOCHS=200\n",
        "tickers3 = [\n",
        "           'AHT', 'AMSC', 'ASTR', 'ATOM',\n",
        "           'BKKT', 'BGFV', 'BGSF', 'CBNT', 'CLOV', \n",
        "           'DNMR', 'ERJ', 'EVGO',\n",
        "           'FSLY',  'FTCH', 'GOGO', 'HIVE', \n",
        "           'ILAL', 'INLX', 'JMIA', 'JOBY',  'KULR', 'MTTR',\n",
        "           'MYTE', 'NEPH', 'ONDS', 'MQ',\n",
        "           'PETS', 'PTON', 'SFIX', 'SFT', 'STNE', \n",
        "           'ULH', 'VRAR', 'WISH']\n",
        "lossfn = \"huber_loss\"\n",
        "# lossfn = \"mean_squared_error\"\n",
        "mod = pipeline.RateReturnOnly(\n",
        "    pipeline.FeatureSeq([pipeline.AddDayMonth(), pipeline.AddVWap(), pipeline.AddMA(200)]))\n",
        "df3, results = pipeline.runModelCombined(tickers3, 'vols', mod, False, loss=lossfn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocQUbPFexMt0"
      },
      "outputs": [],
      "source": [
        "df3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qUk7m7OxMt0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "seq = list()\n",
        "for ticker, result in results.items():\n",
        "    tempdf = result.final_df\n",
        "    tempdf['predicted_rate'] = (tempdf['adjclose_15']-tempdf['adjclose'])/tempdf['adjclose']\n",
        "    tempdf['true_rate'] = (tempdf['true_adjclose_15']-tempdf['adjclose'])/tempdf['adjclose']\n",
        "    seq.append(tempdf[['ticker', 'date', \"predicted_rate\", 'true_rate']])\n",
        "\n",
        "detailstat = pd.concat(seq)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8A-m6zpNxMt0"
      },
      "outputs": [],
      "source": [
        "normalstat = detailstat[detailstat['predicted_rate'].between(-2,2) & detailstat['true_rate'].between(-2,2)]\n",
        "largestat = normalstat[~ normalstat['predicted_rate'].between(-0.25,0.25) & ~ normalstat['true_rate'].between(-0.25,0.25)]\n",
        "largestat.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJuZYVgpxMt1"
      },
      "outputs": [],
      "source": [
        "ax = largestat.plot.scatter(x='predicted_rate', y='true_rate',c='DarkBlue', figsize=(10,10))\n",
        "# ax.set_yscale('log')\n",
        "# ax.set_xscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFvLtoUFxMt1"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.hist([normalstat['predicted_rate'],normalstat['predicted_rate']],\n",
        "#          bins=100, range=(-1,1), color = ['r','g'])\n",
        "\n",
        "corr = largestat[[\"predicted_rate\", \"true_rate\"]].corr()\n",
        "\n",
        "corr.style.background_gradient(cmap='coolwarm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OF4rNi6rxMt1"
      },
      "outputs": [],
      "source": [
        "\n",
        "sns.regplot(x=largestat[\"predicted_rate\"], y=largestat[\"true_rate\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7V3jPQVxMt1"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(normalstat[[\"predicted_rate\", \"true_rate\"]].corr(), annot = True, fmt='.2g',cmap= 'coolwarm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lawcUcT2xMt1",
        "outputId": "1cd08ab6-fd4a-44d1-bfaf-5486fab01862",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sending incremental file list\n",
            "ipos2-3a-adjclose-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "ipos2-3a-high-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "ipos2-3a-low-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-wvwap-wma-adjclose-200-wadj-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n",
            "\n",
            "sent 9,640,232 bytes  received 73 bytes  6,426,870.00 bytes/sec\n",
            "total size is 9,637,296  speedup is 1.00\n"
          ]
        }
      ],
      "source": [
        "!rsync -av --ignore-existing results/* /content/drive/MyDrive/colab/results/\n",
        " "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TestLocal.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}